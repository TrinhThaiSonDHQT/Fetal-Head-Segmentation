{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca120ecd",
   "metadata": {},
   "source": [
    "# Training Experiments - Quick Iteration & Testing\n",
    "\n",
    "This notebook is designed for rapid prototyping and hyperparameter experimentation.\n",
    "\n",
    "**Purpose:**\n",
    "- Quick training runs (5-10 epochs) for fast iteration\n",
    "- Test model architecture changes\n",
    "- Experiment with hyperparameters\n",
    "- Visualize training progress in real-time\n",
    "\n",
    "**For full 100-epoch training, use `main.py` script.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c722ac",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02791d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data import HC18Dataset\n",
    "from src.models import ImprovedUNet\n",
    "from src.losses import DiceBCELoss\n",
    "from src.utils import get_transforms\n",
    "from train import train_one_epoch, evaluate_model\n",
    "\n",
    "# Check device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617d710",
   "metadata": {},
   "source": [
    "## 2. Quick Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXPERIMENT SETTINGS (Adjust for quick tests) ===\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 5  # Quick test (change to 10 for more thorough tests)\n",
    "LEARNING_RATE = 0.001  # Lower LR for quick experiments\n",
    "SUBSET_SIZE = 100  # Use subset for faster iteration (set to None for full dataset)\n",
    "\n",
    "# Data paths\n",
    "TRAIN_IMG_DIR = '../dataset/training_set/images'\n",
    "TRAIN_MASK_DIR = '../dataset/training_set/masks'\n",
    "VAL_IMG_DIR = '../dataset/test_set/images'\n",
    "VAL_MASK_DIR = '../dataset/test_set/masks'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Image Size:      {IMG_HEIGHT}×{IMG_WIDTH}\")\n",
    "print(f\"Batch Size:      {BATCH_SIZE}\")\n",
    "print(f\"Epochs:          {NUM_EPOCHS}\")\n",
    "print(f\"Learning Rate:   {LEARNING_RATE}\")\n",
    "print(f\"Subset Size:     {SUBSET_SIZE if SUBSET_SIZE else 'Full dataset'}\")\n",
    "print(f\"Device:          {DEVICE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1d497",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d33792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "train_transforms = get_transforms(IMG_HEIGHT, IMG_WIDTH, is_train=True)\n",
    "val_transforms = get_transforms(IMG_HEIGHT, IMG_WIDTH, is_train=False)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset_full = HC18Dataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform=train_transforms)\n",
    "val_dataset_full = HC18Dataset(VAL_IMG_DIR, VAL_MASK_DIR, transform=val_transforms)\n",
    "\n",
    "# Use subset for quick experiments\n",
    "if SUBSET_SIZE:\n",
    "    train_indices = np.random.choice(len(train_dataset_full), SUBSET_SIZE, replace=False)\n",
    "    val_indices = np.random.choice(len(val_dataset_full), min(50, len(val_dataset_full)), replace=False)\n",
    "    train_dataset = Subset(train_dataset_full, train_indices)\n",
    "    val_dataset = Subset(val_dataset_full, val_indices)\n",
    "else:\n",
    "    train_dataset = train_dataset_full\n",
    "    val_dataset = val_dataset_full\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
    "                        num_workers=0, pin_memory=True)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5579d56",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58015fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Improved U-Net\n",
    "model = ImprovedUNet(in_channels=1, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE: Improved U-Net\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total parameters:      {total_params:,}\")\n",
    "print(f\"Trainable parameters:  {trainable_params:,}\")\n",
    "print(f\"Model size:            ~{total_params * 4 / (1024**2):.2f} MB (FP32)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = DiceBCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=2\n",
    ")\n",
    "\n",
    "print(f\"\\nLoss Function: Dice + BCE\")\n",
    "print(f\"Optimizer: Adam (LR={LEARNING_RATE})\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau (patience=2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd520cf7",
   "metadata": {},
   "source": [
    "## 5. Quick Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8279842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_dice': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_miou': [],\n",
    "    'val_pa': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_dice = train_one_epoch(\n",
    "        train_loader, model, optimizer, loss_fn, DEVICE, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = evaluate_model(val_loader, model, loss_fn, DEVICE)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_dice'].append(train_dice)\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_dice'].append(val_metrics['dice'])\n",
    "    history['val_miou'].append(val_metrics['miou'])\n",
    "    history['val_pa'].append(val_metrics['pixel_accuracy'])\n",
    "    \n",
    "    # Print\n",
    "    print(f\"Train: Loss={train_loss:.4f}, Dice={train_dice:.4f}\")\n",
    "    print(f\"Val:   Loss={val_metrics['loss']:.4f}, Dice={val_metrics['dice']:.4f}, \"\n",
    "          f\"mIoU={val_metrics['miou']:.4f}, PA={val_metrics['pixel_accuracy']:.4f}\")\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_metrics['dice'])\n",
    "    \n",
    "    # Track best\n",
    "    if val_metrics['dice'] > best_dice:\n",
    "        best_dice = val_metrics['dice']\n",
    "        print(f\"✓ New best Dice: {best_dice:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"TRAINING COMPLETE - Best Dice: {best_dice:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47da880",
   "metadata": {},
   "source": [
    "## 6. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs_range, history['train_loss'], 'o-', label='Train', linewidth=2)\n",
    "axes[0, 0].plot(epochs_range, history['val_loss'], 's-', label='Val', linewidth=2)\n",
    "axes[0, 0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice Score\n",
    "axes[0, 1].plot(epochs_range, history['train_dice'], 'o-', label='Train', linewidth=2)\n",
    "axes[0, 1].plot(epochs_range, history['val_dice'], 's-', label='Val', linewidth=2)\n",
    "axes[0, 1].set_title('Dice Score', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Dice Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# mIoU\n",
    "axes[1, 0].plot(epochs_range, history['val_miou'], 'o-', color='green', linewidth=2)\n",
    "axes[1, 0].set_title('Validation mIoU', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('mIoU')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pixel Accuracy\n",
    "axes[1, 1].plot(epochs_range, history['val_pa'], 'o-', color='purple', linewidth=2)\n",
    "axes[1, 1].set_title('Validation Pixel Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Pixel Accuracy')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b53bdc",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on validation samples\n",
    "model.eval()\n",
    "n_samples = 6\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 4, figsize=(16, 4*n_samples))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, masks) in enumerate(val_loader):\n",
    "        if i >= n_samples:\n",
    "            break\n",
    "            \n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "        \n",
    "        predictions = model(images)\n",
    "        \n",
    "        # Show first image from batch\n",
    "        img = images[0].cpu().squeeze().numpy()\n",
    "        mask = masks[0].cpu().squeeze().numpy()\n",
    "        pred = predictions[0].cpu().squeeze().numpy()\n",
    "        pred_binary = (pred > 0.5).astype(np.float32)\n",
    "        \n",
    "        # Error map\n",
    "        error = np.abs(mask - pred_binary)\n",
    "        \n",
    "        axes[i, 0].imshow(img, cmap='gray')\n",
    "        axes[i, 0].set_title('Input Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred_binary, cmap='gray')\n",
    "        axes[i, 2].set_title('Prediction')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        axes[i, 3].imshow(error, cmap='hot')\n",
    "        axes[i, 3].set_title('Error Map')\n",
    "        axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Predictions on Validation Set', y=1.001, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
