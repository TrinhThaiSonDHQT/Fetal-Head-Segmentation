{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debf4b51",
   "metadata": {},
   "source": [
    "# Standard U-Net Training Notebook (Universal)\n",
    "## Fetal Head Segmentation in Ultrasound Images\n",
    "\n",
    "**Compatible with:** Google Colab, Kaggle, and Local Jupyter\n",
    "\n",
    "This notebook implements a **standard U-Net** baseline model with:\n",
    "1. Standard encoder-decoder architecture with skip connections\n",
    "2. ReLU activations in all convolutional layers\n",
    "3. Padded convolutions (`padding='same'`) to maintain spatial dimensions\n",
    "4. Image normalization (dividing by 255.0)\n",
    "5. Adam optimizer with learning rate 1e-4\n",
    "6. **Dice Loss function** (optimized for class imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1961ec2",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "**Environment Detection:**\n",
    "- **Google Colab**: Clones repository from GitHub to `/content/Fetal-Head-Segmentation`\n",
    "- **Kaggle**: Uses `/kaggle/input/fetal-head-segmentation` for read-only data\n",
    "- **Local**: Uses project structure as-is\n",
    "\n",
    "**Output Directories:**\n",
    "- **Google Colab**: `/content/outputs/` (writable, lost after session)\n",
    "- **Kaggle**: `/kaggle/working/` (writable, downloadable)\n",
    "- **Local**: Project structure as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running on Colab, Kaggle, or locally\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        if os.path.exists('/kaggle/input'):\n",
    "            return 'kaggle'\n",
    "        else:\n",
    "            return 'local'\n",
    "\n",
    "environment = detect_environment()\n",
    "print(f\"Running on: {environment.upper()}\")\n",
    "\n",
    "# Setup paths based on environment\n",
    "if environment == 'colab':\n",
    "    print(\"\\n[Google Colab Setup]\")\n",
    "    \n",
    "    # Clone repository if not already present\n",
    "    repo_path = Path('/content/Fetal-Head-Segmentation')\n",
    "    if not repo_path.exists():\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        !git clone https://github.com/TrinhThaiSonDHQT/Fetal-Head-Segmentation.git /content/Fetal-Head-Segmentation\n",
    "        print(\"✓ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"✓ Repository already exists\")\n",
    "    \n",
    "    project_root = repo_path\n",
    "    output_root = Path('/content/outputs')\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Output root: {output_root}\")\n",
    "    \n",
    "elif environment == 'kaggle':\n",
    "    print(\"\\n[Kaggle Setup]\")\n",
    "    project_root = Path('/kaggle/input/fetal-head-segmentation')\n",
    "    output_root = Path('/kaggle/working')\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    if not project_root.exists():\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset not found at {project_root}\\n\"\n",
    "            f\"Please add the 'fetal-head-segmentation' dataset to your Kaggle notebook.\"\n",
    "        )\n",
    "    \n",
    "    if not (project_root / 'accuracy_focus').exists():\n",
    "        raise RuntimeError(\n",
    "            f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "            f\"Please ensure your dataset structure is correct.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Project root: {project_root} (read-only)\")\n",
    "    print(f\"Output root: {output_root} (writable)\")\n",
    "    \n",
    "else:  # local\n",
    "    print(\"\\n[Local Setup]\")\n",
    "    current = Path(os.getcwd())\n",
    "    project_root = None\n",
    "    \n",
    "    # Find project root\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'accuracy_focus').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "    \n",
    "    if project_root is None:\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot find project root with 'accuracy_focus' folder.\\n\"\n",
    "            f\"Current directory: {os.getcwd()}\"\n",
    "        )\n",
    "    \n",
    "    output_root = project_root / 'accuracy_focus' / 'standard_unet'\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"\\n✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116930d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (for Colab/Kaggle)\n",
    "if environment in ['colab', 'kaggle']:\n",
    "    print(\"Installing/upgrading required packages...\")\n",
    "    !pip install -q albumentations==1.3.1 opencv-python-headless PyYAML tqdm\n",
    "    print(\"✓ Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import from project structure\n",
    "from accuracy_focus.standard_unet.src.models.standard_unet import StandardUNet\n",
    "from accuracy_focus.standard_unet.src.losses import DiceLoss, DiceBCELoss\n",
    "from shared.src.data.cached_dataset import CachedHC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "from shared.src.utils.transforms import get_transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321ab69",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae781dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = project_root / 'accuracy_focus' / 'standard_unet' / 'configs' / 'standard_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Adjust output paths based on environment\n",
    "if environment in ['colab', 'kaggle']:\n",
    "    print(f\"Adjusting paths for {environment.upper()} environment...\")\n",
    "    config['logging']['checkpoint_dir'] = str(output_root / 'results' / 'checkpoints')\n",
    "    config['logging']['log_dir'] = str(output_root / 'results' / 'logs')\n",
    "    config['logging']['prediction_dir'] = str(output_root / 'results' / 'predictions')\n",
    "    config['logging']['visualization_dir'] = str(output_root / 'results' / 'visualizations')\n",
    "    \n",
    "    print(f\"  Outputs will be saved to: {output_root / 'results'}\")\n",
    "\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a3edd",
   "metadata": {},
   "source": [
    "## 3. Initialize Model\n",
    "\n",
    "The Standard U-Net has:\n",
    "- **Encoder**: 4 downsampling blocks (64 → 128 → 256 → 512 channels)\n",
    "- **Bottleneck**: 1024 channels\n",
    "- **Decoder**: 4 upsampling blocks (512 → 256 → 128 → 64 channels)\n",
    "- **Skip Connections**: Concatenate encoder features to decoder\n",
    "- **Activation**: ReLU in all conv layers\n",
    "- **Output**: Sigmoid for binary segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = StandardUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_filters=config['model']['base_filters']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nStandard U-Net Architecture:\")\n",
    "print(f\"  Total trainable parameters: {model.count_parameters():,}\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c2ed7",
   "metadata": {},
   "source": [
    "## 4. Setup Loss and Optimizer\n",
    "\n",
    "- **Loss**: Dice Loss (optimized for class imbalance)\n",
    "- **Optimizer**: Adam with learning rate 1e-4\n",
    "- **Scheduler**: ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (DiceBCELoss - Combined Dice + BCE)\n",
    "loss_config = config['loss']\n",
    "criterion = DiceBCELoss(\n",
    "    dice_weight=loss_config.get('dice_weight', 0.5),\n",
    "    bce_weight=loss_config.get('bce_weight', 0.5),\n",
    "    smooth=loss_config.get('smooth', 1.0)\n",
    ")\n",
    "print(f\"Loss Function: {loss_config['name']}\")\n",
    "print(f\"  Dice weight: {loss_config.get('dice_weight', 0.5)}\")\n",
    "print(f\"  BCE weight: {loss_config.get('bce_weight', 0.5)}\")\n",
    "print(f\"  Smooth parameter: {loss_config.get('smooth', 1.0)}\")\n",
    "\n",
    "# Optimizer (Adam with lr=1e-4)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7dc37a",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders\n",
    "\n",
    "**Preprocessing** (applied to all images):\n",
    "- Images normalized by dividing by 255.0\n",
    "- Resized to 256×256 pixels\n",
    "- Converted to PyTorch tensors (C, H, W)\n",
    "\n",
    "**Augmentation** (training only - applied on-the-fly):\n",
    "- Horizontal flip (p=0.5)\n",
    "- Rotation (±20°, p=0.5)\n",
    "- ShiftScaleRotate: Translation (±10%), Scale (±10%), p=0.5\n",
    "\n",
    "**Note:** Augmentations are applied dynamically during training via Albumentations transforms passed to `CachedHC18Dataset`. Validation uses only preprocessing without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Helper to build paths\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Setup cache directories\n",
    "train_cache_path = str(cache_root / 'train_cache')\n",
    "val_cache_path = str(cache_root / 'val_cache')\n",
    "\n",
    "print(f\"Cache directories:\")\n",
    "print(f\"  Train cache: {train_cache_path}\")\n",
    "print(f\"  Val cache: {val_cache_path}\")\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"\\nCreating augmentation transforms...\")\n",
    "train_transform = get_transforms(height=256, width=256, is_train=True)\n",
    "val_transform = get_transforms(height=256, width=256, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Train dataset - force rebuild to generate fresh cache\n",
    "print(\"\\n[1/2] Building training dataset cache...\")\n",
    "train_dataset = CachedHC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    cache_dir=train_cache_path,\n",
    "    transform=train_transform,\n",
    "    force_rebuild=True\n",
    ")\n",
    "\n",
    "# Validation dataset - force rebuild to generate fresh cache\n",
    "print(\"\\n[2/2] Building validation dataset cache...\")\n",
    "val_dataset = CachedHC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    cache_dir=val_cache_path,\n",
    "    transform=val_transform,\n",
    "    force_rebuild=True\n",
    ")\n",
    "\n",
    "# Adjust num_workers for Colab/Kaggle (avoid multiprocessing issues)\n",
    "num_workers = 0 if environment in ['colab', 'kaggle'] else training_config['num_workers']\n",
    "print(f\"\\nDataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} ({'disabled for Colab/Kaggle' if num_workers == 0 else 'local multi-threading'})\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Normalization: Divide by 255.0\")\n",
    "print(f\"  Train augmentation: ENABLED\")\n",
    "print(f\"  Val augmentation: DISABLED\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abb98c",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdfa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "print(f\"  Mask unique values: {torch.unique(sample_masks)}\")\n",
    "print(f\"  Mask mean (% foreground): {sample_masks.mean():.4f}\")\n",
    "\n",
    "# CRITICAL CHECK: Ensure masks are binary {0, 1}\n",
    "if not torch.all((sample_masks == 0) | (sample_masks == 1)):\n",
    "    print(\"\\n⚠️  WARNING: Masks are not binary! Check preprocessing.\")\n",
    "else:\n",
    "    print(\"\\n✓ Masks are properly binary {0, 1}\")\n",
    "\n",
    "# Check if masks have reasonable foreground ratio (2-10% typical for fetal head)\n",
    "fg_ratio = sample_masks.mean().item()\n",
    "if fg_ratio < 0.01 or fg_ratio > 0.3:\n",
    "    print(f\"⚠️  WARNING: Unusual foreground ratio: {fg_ratio:.2%} (expected 2-10%)\")\n",
    "else:\n",
    "    print(f\"✓ Foreground ratio looks reasonable: {fg_ratio:.2%}\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe5703",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss (Dice Loss)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f1e3a",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - Standard U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: Dice Loss\")\n",
    "print(f\"Optimizer: Adam (lr=1e-4)\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val Dice:   {val_dice:.4f}\")\n",
    "    print(f\"  Val IoU:    {val_iou:.4f}\")\n",
    "    print(f\"  Val PA:     {val_pa:.4f}\")\n",
    "    print(f\"  LR:         {current_lr:.6f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  → Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        print(f\"Best Dice Score: {best_dice:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c8cea",
   "metadata": {},
   "source": [
    "## 9. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba898007",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fae71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get validation samples\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "val_images = val_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    val_preds = model(val_images)\n",
    "    val_preds = (val_preds > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(val_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = val_images[i, 0].cpu().numpy()\n",
    "    mask = val_masks[i, 0].numpy()\n",
    "    pred = val_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    dice = dice_coefficient(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    iou = iou_score(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(val_images[:4].cpu(), val_masks[:4], val_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)\n",
    "print(f\"Sample predictions saved to {pred_dir / 'sample_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0298df",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Model Architecture**: Standard U-Net with skip connections\n",
    "2. **Activation**: ReLU in all convolutional layers\n",
    "3. **Padding**: `padding=1` (same) to maintain spatial dimensions\n",
    "4. **Normalization**: Images divided by 255.0\n",
    "5. **Optimizer**: Adam with learning rate 1e-4\n",
    "6. **Loss Function**: Dice Loss (handles class imbalance)\n",
    "\n",
    "### Results:\n",
    "\n",
    "View the results above and compare with your improved U-Net baseline.\n",
    "\n",
    "### Why Dice Loss?\n",
    "\n",
    "Dice Loss directly optimizes for segmentation overlap, making it more effective than BCE for:\n",
    "- **Class imbalance**: Most pixels are background in medical images\n",
    "- **Small objects**: Fetal head is a small region compared to background\n",
    "- **Direct metric optimization**: Loss matches the evaluation metric (Dice coefficient)\n",
    "\n",
    "---\n",
    "\n",
    "### Platform-Specific Notes:\n",
    "\n",
    "**Google Colab:**\n",
    "- Outputs saved to `/content/outputs/results/`\n",
    "- Download using: `from google.colab import files; files.download('/content/outputs/results/checkpoints/best_model.pth')`\n",
    "\n",
    "**Kaggle:**\n",
    "- Outputs saved to `/kaggle/working/results/`\n",
    "- Automatically available for download after notebook finishes\n",
    "\n",
    "**Local:**\n",
    "- Outputs saved to `accuracy_focus/standard_unet/results/`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
