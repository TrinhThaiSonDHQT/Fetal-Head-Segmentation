{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e8b677",
   "metadata": {},
   "source": [
    "# Standard U-Net Training Notebook\n",
    "## Fetal Head Segmentation in Ultrasound Images\n",
    "\n",
    "This notebook implements a **standard U-Net** baseline model with:\n",
    "1. Standard encoder-decoder architecture with skip connections\n",
    "2. ReLU activations in all convolutional layers\n",
    "3. Padded convolutions (`padding='same'`) to maintain spatial dimensions\n",
    "4. Image normalization (dividing by 255.0)\n",
    "5. Adam optimizer with learning rate 1e-4\n",
    "6. **Dice Loss function** (optimized for class imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78661b22",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "**Environment Detection:**\n",
    "- Automatically detects if running on Kaggle or locally\n",
    "- On Kaggle: Uses `/kaggle/input/fetal-head-segmentation` for read-only data\n",
    "- On Kaggle: Uses `/kaggle/working` for writable outputs (cache, checkpoints, logs)\n",
    "- Locally: Uses project structure as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafabf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-25T04:07:59.646578Z",
     "iopub.status.busy": "2025-10-25T04:07:59.645982Z",
     "iopub.status.idle": "2025-10-25T04:07:59.660193Z",
     "shell.execute_reply": "2025-10-25T04:07:59.659171Z",
     "shell.execute_reply.started": "2025-10-25T04:07:59.646554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Detect environment and set project root\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    # Running on Kaggle\n",
    "    print(\"Running on Kaggle\")\n",
    "    project_root = Path('/kaggle/input/fetal-head-segmentation')\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Project root exists: {project_root.exists()}\")\n",
    "    \n",
    "    if not (project_root / 'accuracy_focus').exists():\n",
    "        raise RuntimeError(\n",
    "            f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "            f\"Please ensure your GitHub repository was added correctly as a Kaggle dataset.\"\n",
    "        )\n",
    "else:\n",
    "    # Running locally\n",
    "    print(\"Running locally\")\n",
    "    current = Path(os.getcwd())\n",
    "    project_root = None\n",
    "    \n",
    "    # Try to find project root by going up\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'accuracy_focus').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "    \n",
    "    if project_root is None:\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot find project root with 'accuracy_focus' folder.\\n\"\n",
    "            f\"Current directory: {os.getcwd()}\"\n",
    "        )\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import from project structure (updated paths)\n",
    "from accuracy_focus.standard_unet.src.models.standard_unet import StandardUNet\n",
    "from accuracy_focus.standard_unet.src.losses import DiceLoss\n",
    "from shared.src.data.cached_dataset import CachedHC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e13f8f9",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from new location\n",
    "config_path = project_root / 'accuracy_focus' / 'standard_unet' / 'configs' / 'standard_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# On Kaggle, adjust output paths to /kaggle/working (input is read-only)\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    print(\"Adjusting paths for Kaggle environment...\")\n",
    "    working_dir = Path('/kaggle/working')\n",
    "    \n",
    "    # Keep cache pointing to read-only input (already preprocessed)\n",
    "    # Only update output directories to writable location\n",
    "    config['logging']['checkpoint_dir'] = str(working_dir / 'results' / 'checkpoints')\n",
    "    config['logging']['log_dir'] = str(working_dir / 'results' / 'logs')\n",
    "    config['logging']['prediction_dir'] = str(working_dir / 'results' / 'predictions')\n",
    "    config['logging']['visualization_dir'] = str(working_dir / 'results' / 'visualizations')\n",
    "    \n",
    "    print(f\"  Cache dir: {config['data']['cache_dir']} (read-only, using existing)\")\n",
    "    print(f\"  Checkpoint dir: {config['logging']['checkpoint_dir']}\")\n",
    "else:\n",
    "    # Running locally - cache should already point to shared/preprocessed_data\n",
    "    print(f\"  Cache dir: {config['data']['cache_dir']}\")\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c928f95",
   "metadata": {},
   "source": [
    "## 3. Initialize Model\n",
    "\n",
    "The Standard U-Net has:\n",
    "- **Encoder**: 4 downsampling blocks (64 → 128 → 256 → 512 channels)\n",
    "- **Bottleneck**: 1024 channels\n",
    "- **Decoder**: 4 upsampling blocks (512 → 256 → 128 → 64 channels)\n",
    "- **Skip Connections**: Concatenate encoder features to decoder\n",
    "- **Activation**: ReLU in all conv layers\n",
    "- **Output**: Sigmoid for binary segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23986bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = StandardUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_filters=config['model']['base_filters']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nStandard U-Net Architecture:\")\n",
    "print(f\"  Total trainable parameters: {model.count_parameters():,}\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a7ba4",
   "metadata": {},
   "source": [
    "## 4. Setup Loss and Optimizer\n",
    "\n",
    "- **Loss**: Dice Loss (optimized for class imbalance)\n",
    "- **Optimizer**: Adam with learning rate 1e-4\n",
    "- **Scheduler**: ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3caad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (Dice Loss)\n",
    "criterion = DiceLoss(smooth=1.0)\n",
    "print(f\"Loss Function: Dice Loss\")\n",
    "print(f\"  Smooth parameter: 1.0\")\n",
    "\n",
    "# Optimizer (Adam with lr=1e-4)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12be19",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders\n",
    "\n",
    "**Preprocessing**:\n",
    "- Images normalized by dividing by 255.0\n",
    "- Resized to 256×256 pixels\n",
    "- Converted to tensors\n",
    "\n",
    "**Augmentation** (training only):\n",
    "- Horizontal flip (p=0.5)\n",
    "- Rotation (±20°, p=0.5)\n",
    "- Scale (±10%, p=0.5)\n",
    "- Translate (±10%, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f747b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Build paths - use config paths directly if already absolute (Kaggle), otherwise join with project_root\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Check if preprocessed cache exists\n",
    "train_cache_path = get_path(data_config['cache_dir'] + '/train_cache')\n",
    "val_cache_path = get_path(data_config['cache_dir'] + '/val_cache')\n",
    "\n",
    "print(\"\\nChecking for existing preprocessed data...\")\n",
    "print(f\"  Train cache: {train_cache_path}\")\n",
    "print(f\"    Exists: {Path(train_cache_path).exists()}\")\n",
    "if Path(train_cache_path).exists():\n",
    "    metadata_file = Path(train_cache_path) / 'metadata.pkl'\n",
    "    print(f\"    Metadata: {metadata_file.exists()}\")\n",
    "\n",
    "print(f\"  Val cache: {val_cache_path}\")\n",
    "print(f\"    Exists: {Path(val_cache_path).exists()}\")\n",
    "if Path(val_cache_path).exists():\n",
    "    metadata_file = Path(val_cache_path) / 'metadata.pkl'\n",
    "    print(f\"    Metadata: {metadata_file.exists()}\")\n",
    "\n",
    "# Train dataset - will use existing cache if available\n",
    "train_dataset = CachedHC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    cache_dir=train_cache_path,\n",
    "    force_rebuild=False  # Explicitly use existing cache if available\n",
    ")\n",
    "\n",
    "# Validation dataset - will use existing cache if available\n",
    "val_dataset = CachedHC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    cache_dir=val_cache_path,\n",
    "    force_rebuild=False  # Explicitly use existing cache if available\n",
    ")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=training_config['num_workers'],\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=training_config['num_workers'],\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\nDatasets:\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Normalization: Divide by 255.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7606b2f",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7220b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3624f1f",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad68df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss (Dice Loss)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a9fad",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15710623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - Standard U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Loss Function: Dice Loss\")\n",
    "print(f\"Optimizer: Adam (lr=1e-4)\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f}\")\n",
    "    print(f\"  Val Dice:   {val_dice:.4f}\")\n",
    "    print(f\"  Val IoU:    {val_iou:.4f}\")\n",
    "    print(f\"  Val PA:     {val_pa:.4f}\")\n",
    "    print(f\"  LR:         {current_lr:.6f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model - use get_path helper for both local and Kaggle\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  → Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        print(f\"Best Dice Score: {best_dice:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867cb70f",
   "metadata": {},
   "source": [
    "## 9. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bdc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure - use get_path helper\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f7d5a",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model - use get_path helper\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get validation samples\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "val_images = val_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    val_preds = model(val_images)\n",
    "    val_preds = (val_preds > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(val_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = val_images[i, 0].cpu().numpy()\n",
    "    mask = val_masks[i, 0].numpy()\n",
    "    pred = val_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    dice = dice_coefficient(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    iou = iou_score(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions - use get_path helper\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(val_images[:4].cpu(), val_masks[:4], val_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)\n",
    "print(f\"Sample predictions saved to {pred_dir / 'sample_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349e986",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Model Architecture**: Standard U-Net with skip connections\n",
    "2. **Activation**: ReLU in all convolutional layers\n",
    "3. **Padding**: `padding=1` (same) to maintain spatial dimensions\n",
    "4. **Normalization**: Images divided by 255.0\n",
    "5. **Optimizer**: Adam with learning rate 1e-4\n",
    "6. **Loss Function**: Dice Loss (handles class imbalance)\n",
    "\n",
    "### Results:\n",
    "\n",
    "View the results above and compare with your improved U-Net baseline.\n",
    "\n",
    "### Why Dice Loss?\n",
    "\n",
    "Dice Loss directly optimizes for segmentation overlap, making it more effective than BCE for:\n",
    "- **Class imbalance**: Most pixels are background in medical images\n",
    "- **Small objects**: Fetal head is a small region compared to background\n",
    "- **Direct metric optimization**: Loss matches the evaluation metric (Dice coefficient)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8567138,
     "sourceId": 13493467,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
