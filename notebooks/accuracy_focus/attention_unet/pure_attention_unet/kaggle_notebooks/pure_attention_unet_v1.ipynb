{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8756ac",
   "metadata": {},
   "source": [
    "# Attention U-Net Training Notebook (Kaggle)\n",
    "## Fetal Head Segmentation in Ultrasound Images\n",
    "\n",
    "**Compatible with:** Kaggle Notebooks\n",
    "\n",
    "This notebook implements an **Attention U-Net** architecture with:\n",
    "1. Standard U-Net encoder/decoder with convolutional blocks\n",
    "2. **Attention Gates** applied to skip connections before concatenation\n",
    "3. Spatial attention mechanism to focus on relevant features\n",
    "4. Improved feature selection through gating mechanism\n",
    "\n",
    "**Key Innovation:** Attention Gates weight the skip connections from the encoder, allowing the network to focus on relevant spatial regions and suppress irrelevant activations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57803ae",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "**Kaggle Environment:**\n",
    "- Uses `/kaggle/input/fhs-attention-unet` for read-only project data\n",
    "- Uses `/kaggle/working/` for writable outputs (checkpoints, logs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"[Kaggle Setup]\")\n",
    "\n",
    "# Setup paths for Kaggle\n",
    "project_root = Path('/kaggle/input/fhs-attention-unet')\n",
    "output_root = Path('/kaggle/working')\n",
    "cache_root = output_root / 'cache'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not project_root.exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Dataset not found at {project_root}\\n\"\n",
    "        f\"Please add the 'fhs-attention-unet' dataset to your Kaggle notebook.\"\n",
    "    )\n",
    "\n",
    "if not (project_root / 'accuracy_focus').exists():\n",
    "    raise RuntimeError(\n",
    "        f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "        f\"Please ensure your dataset structure is correct.\"\n",
    "    )\n",
    "\n",
    "print(f\"Project root: {project_root} (read-only)\")\n",
    "print(f\"Output root: {output_root} (writable)\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"\\n✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeeacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Kaggle\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# This ensures override Kaggle's pre-installed packages\n",
    "!pip install --force-reinstall --no-cache-dir -q \\\n",
    "    \"numpy==1.26.4\" \\\n",
    "    \"scipy==1.11.4\" \\\n",
    "    \"scikit-learn==1.5.1\" \\\n",
    "    \"albumentations==1.4.0\" \\\n",
    "    \"opencv-python-headless==4.9.0.80\" \\\n",
    "    \"PyYAML>=5.4\" \\\n",
    "    \"tqdm>=4.62\"\n",
    "\n",
    "print(\"\\n✓ Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126700b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ===== OLD IMPORTS (commented out) =====\n",
    "from accuracy_focus.attention_unet.src.losses.dice_loss import DiceLoss\n",
    "from accuracy_focus.attention_unet.src.models.attention_unet import AttentionUNet\n",
    "\n",
    "# ===== NEW IMPORTS (BCEWithLogits + Logits Model) =====\n",
    "# from accuracy_focus.attention_unet.src.losses.bce_logits import DiceBCEWithLogitsLoss\n",
    "# from accuracy_focus.attention_unet.src.models.attention_unet.bce_logits_attention_unet import AttentionUNetLogits\n",
    "\n",
    "from shared.src.data import HC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "from shared.src.utils.transforms import get_transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c34d7",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = project_root / 'accuracy_focus' / 'attention_unet' / 'configs' / 'attention_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Adjust output paths for Kaggle environment\n",
    "print(f\"Adjusting paths for Kaggle environment...\")\n",
    "config['logging']['checkpoint_dir'] = str(output_root / 'results' / 'checkpoints')\n",
    "config['logging']['log_dir'] = str(output_root / 'results' / 'logs')\n",
    "config['logging']['prediction_dir'] = str(output_root / 'results' / 'predictions')\n",
    "config['logging']['visualization_dir'] = str(output_root / 'results' / 'visualizations')\n",
    "\n",
    "print(f\"  Outputs will be saved to: {output_root / 'results'}\")\n",
    "\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fe73f",
   "metadata": {},
   "source": [
    "## 3. Initialize Model\n",
    "\n",
    "The Attention U-Net has:\n",
    "- **Encoder**: 4 downsampling blocks with ConvBlock (64 → 128 → 256 → 512 channels)\n",
    "- **Bottleneck**: ConvBlock (1024 channels)\n",
    "- **Decoder**: 4 upsampling blocks with ConvBlock (512 → 256 → 128 → 64 channels)\n",
    "- **Attention Gates**: Applied to skip connections before concatenation with decoder features\n",
    "- **Skip Connections**: Attention-weighted features from encoder concatenated with decoder\n",
    "- **Activation**: ReLU in convolutional blocks, Sigmoid output\n",
    "- **Spatial Attention**: Attention gates focus on relevant spatial regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573de887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===== OLD MODEL (commented out) =====\n",
    "model = AttentionUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_filters=config['model']['base_filters'],\n",
    "    use_sigmoid=True  # Old model uses sigmoid\n",
    ")\n",
    "\n",
    "# ===== NEW MODEL (AttentionUNetLogits - no sigmoid) =====\n",
    "# model = AttentionUNetLogits(\n",
    "#     in_channels=config['model']['in_channels'],\n",
    "#     out_channels=config['model']['out_channels'],\n",
    "#     base_filters=config['model']['base_filters']\n",
    "#     # No sigmoid - outputs logits for BCEWithLogitsLoss\n",
    "# )\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nAttention U-Net Architecture (Logits Version):\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: ~{total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "print(f\"  Output type: LOGITS (no sigmoid)\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range (logits): [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")\n",
    "print(f\"  Note: Outputs are logits, not probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1984",
   "metadata": {},
   "source": [
    "## 4. Setup Loss and Optimizer\n",
    "\n",
    "- **Loss**: DiceLoss (Sorensen-Dice Loss)\n",
    "- **Optimizer**: Adam with learning rate from config\n",
    "- **Scheduler**: ReduceLROnPlateau (monitors validation Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== OLD LOSS FUNCTION (commented out) =====\n",
    "loss_config = config['loss']\n",
    "criterion = DiceLoss(smooth=1e-6)\n",
    "print(f\"Loss Function: {loss_config['name']}\")\n",
    "print(f\"  Smooth parameter: 1e-6\")\n",
    "\n",
    "# ===== NEW LOSS FUNCTION (DiceBCEWithLogitsLoss) =====\n",
    "# loss_config = config['loss']\n",
    "# criterion = DiceBCEWithLogitsLoss(\n",
    "#     dice_weight=0.5,\n",
    "#     bce_weight=0.5,\n",
    "#     pos_weight=None,  # Will be auto-computed from first batch\n",
    "#     auto_weight=True,  # Automatic pos_weight calculation\n",
    "#     smooth=1e-6\n",
    "# )\n",
    "# print(f\"Loss Function: DiceBCEWithLogitsLoss (NEW - handles class imbalance)\")\n",
    "# print(f\"  Dice weight: 0.5\")\n",
    "# print(f\"  BCE weight: 0.5\")\n",
    "# print(f\"  Smooth parameter: 1e-6\")\n",
    "# print(f\"  Auto pos_weight: True (computed from first batch)\")\n",
    "# print(f\"  → This loss handles extreme class imbalance automatically\")\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"\\nOptimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "print(f\"  Weight decay: {optimizer_config['weight_decay']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"\\nScheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644156e8",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders\n",
    "\n",
    "**Preprocessing** (applied to all images):\n",
    "- Images normalized by dividing by 255.0\n",
    "- Resized to 256×256 pixels\n",
    "- Converted to PyTorch tensors (C, H, W)\n",
    "\n",
    "**Augmentation** (training only - applied on-the-fly):\n",
    "- Horizontal & Vertical flip (p=0.5)\n",
    "- Rotation (±20°, p=0.5)\n",
    "- ShiftScaleRotate: Translation (±10%), Scale (±10%), p=0.5\n",
    "\n",
    "**Note:** Augmentations are applied dynamically during training. Fresh augmented samples are generated every epoch for better model generalization. Validation uses only preprocessing without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad39041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Helper to build paths\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"Creating augmentation transforms...\")\n",
    "train_transform = get_transforms(height=256, width=256, is_train=True)\n",
    "val_transform = get_transforms(height=256, width=256, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Create datasets - using HC18Dataset for on-the-fly augmentation\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Use num_workers=0 for Kaggle to avoid multiprocessing issues\n",
    "num_workers = 0\n",
    "print(f\"\\nDataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} (disabled for Kaggle)\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Train augmentation: ENABLED (on-the-fly)\")\n",
    "print(f\"  Val augmentation: DISABLED\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8cd7a9",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "print(f\"  Mask unique values: {torch.unique(sample_masks)}\")\n",
    "print(f\"  Mask mean (% foreground): {sample_masks.mean():.4f}\")\n",
    "\n",
    "# CRITICAL CHECK: Ensure masks are binary {0, 1}\n",
    "if not torch.all((sample_masks == 0) | (sample_masks == 1)):\n",
    "    print(\"\\n⚠️  WARNING: Masks are not binary! Check preprocessing.\")\n",
    "else:\n",
    "    print(\"\\n✓ Masks are properly binary {0, 1}\")\n",
    "\n",
    "# Check if masks have reasonable foreground ratio (2-10% typical for fetal head)\n",
    "fg_ratio = sample_masks.mean().item()\n",
    "if fg_ratio < 0.01 or fg_ratio > 0.3:\n",
    "    print(f\"⚠️  WARNING: Unusual foreground ratio: {fg_ratio:.2%} (expected 2-10%)\")\n",
    "else:\n",
    "    print(f\"✓ Foreground ratio looks reasonable: {fg_ratio:.2%}\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef2a42",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c608eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            # IMPORTANT: Model outputs LOGITS, need sigmoid before thresholding\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f480d",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cfde12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - Attention U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):    \n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    dice_indicator = ' 🏆' if val_dice > best_dice else ''\n",
    "    lr_change = f' ⬇️ (reduced from {old_lr:.6f})' if current_lr < old_lr else ''\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}{dice_indicator}\")\n",
    "    print(f\"Val mIoU: {val_iou:.4f} | Val mPA: {val_pa:.4f}\")\n",
    "    if lr_change: print(f\"LR: {current_lr:.6f}{lr_change}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model_attention_unet.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  → Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  ⚠️  No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"⛔ EARLY STOPPING TRIGGERED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Stopped at epoch: {epoch+1}\")\n",
    "        print(f\"  Best Dice Score:  {best_dice:.4f}\")\n",
    "        print(f\"  Patience limit:   {patience} epochs without improvement\")\n",
    "        print(f\"{'='*70}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8493591c",
   "metadata": {},
   "source": [
    "## 9. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0675355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9c474",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model_attention_unet.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get validation samples\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "val_images = val_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    # IMPORTANT: Model outputs LOGITS, apply sigmoid to get probabilities\n",
    "    val_logits = model(val_images)\n",
    "    val_preds = (torch.sigmoid(val_logits) > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(val_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = val_images[i, 0].cpu().numpy()\n",
    "    mask = val_masks[i, 0].numpy()\n",
    "    pred = val_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    dice = dice_coefficient(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    iou = iou_score(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(val_images[:4].cpu(), val_masks[:4], val_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d6797",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Innovations:\n",
    "\n",
    "1. **Attention Gates on Skip Connections**: Spatial attention mechanism weights encoder features before concatenation\n",
    "   - Focuses on relevant spatial regions\n",
    "   - Suppresses irrelevant activations\n",
    "   - Improves feature selection\n",
    "\n",
    "2. **Standard U-Net Backbone**: Proven encoder-decoder architecture with skip connections\n",
    "\n",
    "3. **Improved Feature Selection**: Attention mechanism helps the network focus on the fetal head region\n",
    "\n",
    "### Architecture Highlights:\n",
    "\n",
    "- **Encoder**: 4 stages with ConvBlock (64→128→256→512)\n",
    "- **Bottleneck**: ConvBlock (1024 channels)\n",
    "- **Decoder**: 4 stages with ConvBlock + Attention Gates (512→256→128→64)\n",
    "- **Total Parameters**: ~34M parameters (~131 MB)\n",
    "\n",
    "### Training Configuration:\n",
    "\n",
    "- **Loss**: DiceLoss (Sorensen-Dice Loss)\n",
    "- **Optimizer**: Adam (lr from config, weight decay)\n",
    "- **Scheduler**: ReduceLROnPlateau (monitors validation Dice)\n",
    "- **Augmentation**: HorizontalFlip, Rotation, ShiftScaleRotate (on-the-fly)\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "The Attention Gates should improve segmentation accuracy by:\n",
    "- Better boundary detection through spatial attention\n",
    "- Improved focus on relevant regions (fetal head)\n",
    "- Reduced false positives by suppressing background features\n",
    "\n",
    "### Results:\n",
    "\n",
    "View the training curves and predictions above. Compare with:\n",
    "- **Standard U-Net**: Baseline performance\n",
    "- **Residual SE U-Net**: Channel attention approach\n",
    "- **ASPP-Enhanced models**: Multi-scale feature extraction\n",
    "\n",
    "---\n",
    "\n",
    "### Kaggle-Specific Notes:\n",
    "\n",
    "**Kaggle:**\n",
    "- Outputs saved to `/kaggle/working/results/`\n",
    "- Automatically available for download after notebook finishes\n",
    "- Best model: `best_model_attention_unet.pth`\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Compare with Standard U-Net and other variants\n",
    "2. Analyze attention maps to understand what the network focuses on\n",
    "3. Test on HC18 test set\n",
    "4. Experiment with different attention configurations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
