{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7709760",
   "metadata": {},
   "source": [
    "# Fetal Head Segmentation Training (Universal - Colab/Kaggle Compatible)\n",
    "\n",
    "This notebook implements the complete training pipeline for the Improved U-Net model.\n",
    "\n",
    "**Target Performance Metrics:**\n",
    "- DSC (Dice Similarity Coefficient): ≥97.81%\n",
    "- mIoU (Mean Intersection over Union): ≥97.90%\n",
    "- mPA (Mean Pixel Accuracy): ≥99.18%\n",
    "\n",
    "**Platforms Supported:**\n",
    "- ✅ Google Colab\n",
    "- ✅ Kaggle Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243ca49",
   "metadata": {},
   "source": [
    "## 1. Setup Environment & Platform Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76184b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PLATFORM DETECTION\n",
      "======================================================================\n",
      "✓ Running locally\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Detect platform\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Platform detection\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ or 'google.colab' in sys.modules\n",
    "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PLATFORM DETECTION\")\n",
    "print(\"=\"*70)\n",
    "if IS_COLAB:\n",
    "    print(\"✓ Running on Google Colab\")\n",
    "    PLATFORM = 'colab'\n",
    "elif IS_KAGGLE:\n",
    "    print(\"✓ Running on Kaggle\")\n",
    "    PLATFORM = 'kaggle'\n",
    "else:\n",
    "    print(\"✓ Running locally\")\n",
    "    PLATFORM = 'local'\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447e9102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch version: 2.9.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9983519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if needed)\n",
    "if PLATFORM == 'colab':\n",
    "    !pip install albumentations==1.3.1 -q\n",
    "    !pip install pyyaml -q\n",
    "    print(\"✓ Packages installed for Colab\")\n",
    "elif PLATFORM == 'kaggle':\n",
    "    # Kaggle has most packages pre-installed, install only if needed\n",
    "    try:\n",
    "        import albumentations\n",
    "        print(f\"✓ Albumentations version: {albumentations.__version__}\")\n",
    "    except ImportError:\n",
    "        !pip install albumentations==1.3.1 -q\n",
    "        print(\"✓ Installed albumentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cabdc",
   "metadata": {},
   "source": [
    "## 2. Setup Paths (Platform-Specific)\n",
    "\n",
    "### For Google Colab:\n",
    "1. Automatically clones repository from GitHub to `/content/Fetal-Head-Segmentation`\n",
    "2. Outputs saved to `/content/outputs/` (writable, lost after session)\n",
    "\n",
    "### For Kaggle:\n",
    "1. Upload your project as a Kaggle Dataset named `fetal-head-segmentation`\n",
    "2. Add it as input to your notebook\n",
    "3. Outputs saved to `/kaggle/working/` (writable, downloadable)\n",
    "\n",
    "### For Local:\n",
    "1. Automatically detects project root by finding `accuracy_focus` folder\n",
    "2. Outputs saved to project structure as configured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project path: e:\\Fetal Head Segmentation\\notebooks\n",
      "\n",
      "Project files: ['01_data_exploration.ipynb', '02_training_experiments.ipynb', '03_results_analysis.ipynb', 'FHS_Accuracy_Focus.ipynb', 'FHS_Accuracy_Focus_Universal.ipynb', 'rebuild_cache.ipynb', 'results.txt']\n"
     ]
    }
   ],
   "source": [
    "# Platform-specific path configuration\n",
    "if PLATFORM == 'colab':\n",
    "    print(\"\\n[Google Colab Setup]\")\n",
    "    \n",
    "    # Clone repository if not already present\n",
    "    repo_path = Path('/content/Fetal-Head-Segmentation')\n",
    "    if not repo_path.exists():\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        !git clone https://github.com/TrinhThaiSonDHQT/Fetal-Head-Segmentation.git /content/Fetal-Head-Segmentation\n",
    "        print(\"✓ Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"✓ Repository already exists\")\n",
    "    \n",
    "    PROJECT_PATH = repo_path\n",
    "    OUTPUT_PATH = Path('/content/outputs')\n",
    "    CACHE_ROOT = OUTPUT_PATH / 'cache'\n",
    "    \n",
    "    print(f\"✓ Project path: {PROJECT_PATH}\")\n",
    "    print(f\"✓ Output path: {OUTPUT_PATH}\")\n",
    "\n",
    "elif PLATFORM == 'kaggle':\n",
    "    print(\"\\n[Kaggle Setup]\")\n",
    "    PROJECT_PATH = Path('/kaggle/input/fetal-head-segmentation')\n",
    "    OUTPUT_PATH = Path('/kaggle/working')\n",
    "    CACHE_ROOT = OUTPUT_PATH / 'cache'\n",
    "    \n",
    "    if not PROJECT_PATH.exists():\n",
    "        # Fallback: look for any mounted dataset\n",
    "        input_datasets = os.listdir('/kaggle/input')\n",
    "        if input_datasets:\n",
    "            PROJECT_PATH = Path(f'/kaggle/input/{input_datasets[0]}')\n",
    "            print(f\"⚠️ Using available dataset: {input_datasets[0]}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\n",
    "                \"No datasets found in /kaggle/input/\\n\"\n",
    "                \"Please add the 'fetal-head-segmentation' dataset to your Kaggle notebook.\"\n",
    "            )\n",
    "    \n",
    "    if not (PROJECT_PATH / 'accuracy_focus').exists():\n",
    "        raise RuntimeError(\n",
    "            f\"'accuracy_focus' folder not found in {PROJECT_PATH}\\n\"\n",
    "            f\"Please ensure your dataset structure is correct.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Project path (read-only): {PROJECT_PATH}\")\n",
    "    print(f\"✓ Output path: {OUTPUT_PATH}\")\n",
    "\n",
    "else:  # local\n",
    "    print(\"\\n[Local Setup]\")\n",
    "    current = Path(os.getcwd())\n",
    "    PROJECT_PATH = None\n",
    "    \n",
    "    # Find project root by looking for 'accuracy_focus' folder\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'accuracy_focus').exists():\n",
    "            PROJECT_PATH = parent\n",
    "            break\n",
    "    \n",
    "    if PROJECT_PATH is None:\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot find project root with 'accuracy_focus' folder.\\n\"\n",
    "            f\"Current directory: {os.getcwd()}\"\n",
    "        )\n",
    "    \n",
    "    OUTPUT_PATH = PROJECT_PATH / 'accuracy_focus' / 'improved_unet'\n",
    "    CACHE_ROOT = OUTPUT_PATH / 'cache'\n",
    "    \n",
    "    print(f\"✓ Project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.insert(0, str(PROJECT_PATH))\n",
    "\n",
    "print(f\"\\nProject files: {os.listdir(PROJECT_PATH)[:10]}\")  # Show first 10 files\n",
    "print(f\"\\n✓ Environment setup complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf369c4e",
   "metadata": {},
   "source": [
    "## 3. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a19032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import from shared modules\n",
    "from shared.configs.config_loader import load_config\n",
    "from shared.src.utils import get_transforms, get_optimizer\n",
    "from shared.src.utils.train import train_one_epoch, evaluate_model\n",
    "\n",
    "# Import model and loss from improved_unet package\n",
    "from accuracy_focus.improved_unet.src.models import ImprovedUNet\n",
    "from accuracy_focus.improved_unet.src.losses import DiceBCELoss\n",
    "\n",
    "print(\"✓ All imports successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab301612",
   "metadata": {},
   "source": [
    "## 4. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced5230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from improved_unet configs\n",
    "config_path = PROJECT_PATH / 'accuracy_focus' / 'improved_unet' / 'configs' / 'improved_unet_config.yaml'\n",
    "config = load_config(str(config_path))\n",
    "\n",
    "# Extract config values\n",
    "data_cfg = config['data']\n",
    "model_cfg = config['model']\n",
    "train_cfg = config['training']\n",
    "aug_cfg = config['augmentation']\n",
    "checkpoint_cfg = config['checkpoint']\n",
    "logging_cfg = config['logging']\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Helper function to get paths\n",
    "def get_data_path(relative_path):\n",
    "    \"\"\"Convert relative path to absolute path based on platform\"\"\"\n",
    "    return str(PROJECT_PATH / relative_path)\n",
    "\n",
    "# Create output directories based on platform\n",
    "if PLATFORM in ['colab', 'kaggle']:\n",
    "    # Colab/Kaggle: save to writable directories\n",
    "    checkpoint_dir = OUTPUT_PATH / 'results' / 'checkpoints'\n",
    "    log_dir = OUTPUT_PATH / 'results' / 'logs'\n",
    "    prediction_dir = OUTPUT_PATH / 'results' / 'predictions'\n",
    "    visualization_dir = OUTPUT_PATH / 'results' / 'visualizations'\n",
    "    \n",
    "    print(f\"Adjusting paths for {PLATFORM.upper()} environment...\")\n",
    "    print(f\"  Outputs will be saved to: {OUTPUT_PATH / 'results'}\")\n",
    "else:\n",
    "    # Local: use config paths (pointing to improved_unet folder)\n",
    "    checkpoint_dir = PROJECT_PATH / 'accuracy_focus' / 'improved_unet' / checkpoint_cfg['save_dir']\n",
    "    log_dir = PROJECT_PATH / 'accuracy_focus' / 'improved_unet' / logging_cfg['log_dir']\n",
    "    prediction_dir = PROJECT_PATH / 'accuracy_focus' / 'improved_unet' / logging_cfg['prediction_dir']\n",
    "    visualization_dir = PROJECT_PATH / 'accuracy_focus' / 'improved_unet' / logging_cfg['visualization_dir']\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "if logging_cfg.get('save_predictions', False):\n",
    "    os.makedirs(prediction_dir, exist_ok=True)\n",
    "    os.makedirs(visualization_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FETAL HEAD SEGMENTATION - IMPROVED U-NET TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Platform: {PLATFORM.upper()}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Batch Size: {train_cfg['batch_size']}\")\n",
    "print(f\"Learning Rate: {train_cfg['optimizer']['lr']}\")\n",
    "print(f\"Number of Epochs: {train_cfg['num_epochs']}\")\n",
    "print(f\"Checkpoints: {checkpoint_dir}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc6936",
   "metadata": {},
   "source": [
    "## 5. Prepare Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[1/4] Loading datasets...\\n\")\n",
    "\n",
    "# Get image size from config\n",
    "img_size = aug_cfg['preprocessing']['image_size'][0]  # Assuming square images\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"Creating augmentation transforms...\")\n",
    "train_transforms = get_transforms(img_size, img_size, is_train=True)\n",
    "val_transforms = get_transforms(img_size, img_size, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Create datasets - use standard HC18Dataset for on-the-fly augmentation\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = HC18Dataset(\n",
    "    get_data_path(data_cfg['train_images']), \n",
    "    get_data_path(data_cfg['train_masks']), \n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = HC18Dataset(\n",
    "    get_data_path(data_cfg['val_images']), \n",
    "    get_data_path(data_cfg['val_masks']), \n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples available at: {get_data_path(data_cfg['test_images'])}\")\n",
    "print(f\"  Image size: {img_size}×{img_size}\")\n",
    "print(f\"  Normalization: Divide by 255.0\")\n",
    "print(f\"  Train augmentation: ENABLED (applied on-the-fly)\")\n",
    "print(f\"  Val augmentation: DISABLED\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Adjust num_workers for Colab/Kaggle (avoid multiprocessing issues)\n",
    "num_workers = 0 if PLATFORM in ['colab', 'kaggle'] else train_cfg['num_workers']\n",
    "print(f\"DataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} ({'disabled for Colab/Kaggle' if num_workers == 0 else 'local multi-threading'})\")\n",
    "print(f\"  Batch size: {train_cfg['batch_size']}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=train_cfg['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=train_cfg['pin_memory']\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=train_cfg['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=train_cfg['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Data loaders created\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2e664",
   "metadata": {},
   "source": [
    "## 6. Initialize Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1df26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[2/4] Initializing model...\\n\")\n",
    "\n",
    "# Initialize Improved U-Net model\n",
    "model = ImprovedUNet(\n",
    "    in_channels=model_cfg['in_channels'], \n",
    "    out_channels=model_cfg['out_channels']\n",
    ").to(device)\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# CRITICAL FIX: Loss function with weighted BCE for class imbalance\n",
    "loss_cfg = train_cfg['loss']\n",
    "\n",
    "# Calculate pos_weight based on foreground ratio (default 200 for ~0.4% foreground)\n",
    "# pos_weight = background_pixels / foreground_pixels\n",
    "foreground_ratio = 0.004  # ~0.4% from HC18 dataset\n",
    "pos_weight = (1 - foreground_ratio) / foreground_ratio\n",
    "print(f\"\\n⚠️  CRITICAL: Class imbalance detected!\")\n",
    "print(f\"   Foreground: {foreground_ratio*100:.2f}%, Background: {(1-foreground_ratio)*100:.2f}%\")\n",
    "print(f\"   Using BCEWithLogitsLoss with pos_weight={pos_weight:.1f}\")\n",
    "\n",
    "# CRITICAL: Create pos_weight tensor on the SAME device as model\n",
    "pos_weight_tensor = torch.tensor([pos_weight], device=device)\n",
    "\n",
    "loss_fn = DiceBCELoss(\n",
    "    dice_weight=loss_cfg.get('dice_weight', 0.8),  # Default 0.8 (prioritize Dice)\n",
    "    bce_weight=loss_cfg.get('bce_weight', 0.2),    # Default 0.2\n",
    "    pos_weight=pos_weight_tensor  # CRITICAL: Must be on same device as model\n",
    ")\n",
    "print(f\"Loss: DiceBCELoss (dice_weight={loss_cfg.get('dice_weight', 0.8)}, bce_weight={loss_cfg.get('bce_weight', 0.2)})\")\n",
    "print(f\"      BCE uses pos_weight={pos_weight:.1f} on device={device}\")\n",
    "\n",
    "# Optimizer - supports both SGD and Adam\n",
    "optimizer_cfg = train_cfg['optimizer']\n",
    "optimizer = get_optimizer(model, optimizer_cfg)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_cfg = train_cfg['scheduler']\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode=scheduler_cfg['mode'],\n",
    "    factor=scheduler_cfg['factor'],\n",
    "    patience=scheduler_cfg['patience'],\n",
    "    min_lr=scheduler_cfg['min_lr']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9d2cf",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[3/4] Starting training...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_dice = 0.0\n",
    "early_stopping_patience = train_cfg.get('early_stopping_patience', 15)  # Default: 15 epochs\n",
    "early_stopping_counter = 0\n",
    "early_stopped = False\n",
    "\n",
    "print(f\"Early stopping enabled with patience: {early_stopping_patience} epochs\\n\")\n",
    "\n",
    "for epoch in range(1, train_cfg['num_epochs'] + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{train_cfg['num_epochs']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_dice = train_one_epoch(\n",
    "        train_loader, model, optimizer, loss_fn, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_metrics = evaluate_model(val_loader, model, loss_fn, device)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}\")\n",
    "    print(f\"Val Loss: {val_metrics['loss']:.4f} | Val Dice: {val_metrics['dice']:.4f}\")\n",
    "    print(f\"Val mIoU: {val_metrics['miou']:.4f} | Val mPA: {val_metrics['pixel_accuracy']:.4f}\")\n",
    "    \n",
    "    # Update learning rate based on validation Dice\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_metrics['dice'])\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr != current_lr:\n",
    "        print(f\"Learning rate reduced: {current_lr:.6f} → {new_lr:.6f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    if val_metrics['dice'] > best_dice:\n",
    "        best_dice = val_metrics['dice']\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        if checkpoint_cfg['save_best']:\n",
    "            save_path = checkpoint_dir / 'best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dice': best_dice,\n",
    "                'val_metrics': val_metrics,\n",
    "                'config': config\n",
    "            }, str(save_path))\n",
    "            print(f\"✓ Saved best model with Dice: {best_dice:.4f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "        \n",
    "        # Check if early stopping should trigger\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"\\n⚠️ Early stopping triggered! No improvement for {early_stopping_patience} epochs.\")\n",
    "            early_stopped = True\n",
    "    \n",
    "    # Save last checkpoint\n",
    "    if checkpoint_cfg['save_last']:\n",
    "        save_path = checkpoint_dir / 'last_model.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_metrics': val_metrics,\n",
    "            'config': config\n",
    "        }, str(save_path))\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        save_path = checkpoint_dir / f'checkpoint_epoch_{epoch}.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'config': config\n",
    "        }, str(save_path))\n",
    "        print(f\"✓ Saved checkpoint at epoch {epoch}\")\n",
    "    \n",
    "    # Break if early stopping triggered\n",
    "    if early_stopped:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d1a69",
   "metadata": {},
   "source": [
    "## 8. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64449bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best Dice Score: {best_dice:.4f} ({best_dice*100:.2f}%)\")\n",
    "print(f\"Best model saved at: {checkpoint_dir / 'best_model.pth'}\")\n",
    "\n",
    "# Print early stopping info\n",
    "if early_stopped:\n",
    "    print(f\"\\n⚠️ Training stopped early at epoch {epoch} (no improvement for {early_stopping_patience} epochs)\")\n",
    "else:\n",
    "    print(f\"\\n✓ Completed all {train_cfg['num_epochs']} epochs\")\n",
    "\n",
    "# Print target metrics comparison\n",
    "target_metrics = config.get('target_metrics', {})\n",
    "if target_metrics:\n",
    "    print(\"\\nTarget Performance Metrics:\")\n",
    "    print(f\"  Target Dice: {target_metrics.get('dice', 0)*100:.2f}% | Achieved: {best_dice*100:.2f}%\")\n",
    "    \n",
    "    if best_dice >= target_metrics.get('dice', 0):\n",
    "        print(\"\\n🎉 Target Dice score achieved!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ Target not reached. Gap: {(target_metrics.get('dice', 0) - best_dice)*100:.2f}%\")\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34e5c9",
   "metadata": {},
   "source": [
    "## 9. Download Trained Model\n",
    "\n",
    "### Google Colab: \n",
    "- Downloads directly to your browser\n",
    "\n",
    "### Kaggle: \n",
    "- Files saved to `/kaggle/working/results/` (auto-downloaded when notebook finishes)\n",
    "\n",
    "### Local:\n",
    "- Files saved to `accuracy_focus/improved_unet/results/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e608c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = checkpoint_dir / 'best_model.pth'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    if PLATFORM == 'colab':\n",
    "        from google.colab import files\n",
    "        files.download(str(best_model_path))\n",
    "        print(f\"✓ Downloaded: {best_model_path}\")\n",
    "    elif PLATFORM == 'kaggle':\n",
    "        print(f\"✓ Model saved at: {best_model_path}\")\n",
    "        print(f\"✓ Files in /kaggle/working will be auto-downloaded when notebook completes\")\n",
    "        print(f\"\\nSaved files:\")\n",
    "        for f in os.listdir(checkpoint_dir):\n",
    "            print(f\"  - {f}\")\n",
    "    else:\n",
    "        print(f\"✓ Model saved at: {best_model_path}\")\n",
    "else:\n",
    "    print(\"⚠️ Best model not found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfae128",
   "metadata": {},
   "source": [
    "## 10. Visualize Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a batch from validation set\n",
    "with torch.no_grad():\n",
    "    images, masks = next(iter(val_loader))\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    \n",
    "    # CRITICAL FIX: Model outputs logits, apply sigmoid for visualization\n",
    "    logits = model(images)\n",
    "    probs = torch.sigmoid(logits)  # Convert logits to probabilities [0, 1]\n",
    "    preds = (probs > 0.5).float()  # Threshold at 0.5\n",
    "\n",
    "# Visualize first 4 samples\n",
    "num_samples = min(4, images.shape[0])\n",
    "fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Original image\n",
    "    img = images[i].cpu().squeeze().numpy()\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth mask\n",
    "    mask = masks[i].cpu().squeeze().numpy()\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Probability heatmap (NEW: show model confidence)\n",
    "    prob = probs[i].cpu().squeeze().numpy()\n",
    "    axes[i, 2].imshow(prob, cmap='jet', vmin=0, vmax=1)\n",
    "    axes[i, 2].set_title('Prediction Probability')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Binary prediction\n",
    "    pred = preds[i].cpu().squeeze().numpy()\n",
    "    axes[i, 3].imshow(pred, cmap='gray')\n",
    "    \n",
    "    # Calculate Dice for this sample\n",
    "    dice = (2 * (pred * mask).sum()) / (pred.sum() + mask.sum() + 1e-6)\n",
    "    axes[i, 3].set_title(f'Binary Prediction (Dice: {dice:.3f})')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization complete\")\n",
    "print(\"  Note: Model outputs logits → sigmoid applied for visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
