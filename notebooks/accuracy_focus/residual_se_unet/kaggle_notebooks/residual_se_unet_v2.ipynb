{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41719aef",
   "metadata": {},
   "source": [
    "# Residual SE U-Net for Fetal Head Segmentation\n",
    "## Training Notebook (Kaggle Compatible)\n",
    "\n",
    "**Platform:** Kaggle Notebooks with GPU acceleration\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "This notebook implements a **Residual SE U-Net** for medical image segmentation with the following components:\n",
    "\n",
    "**Core Architecture:**\n",
    "- U-Net encoder-decoder structure with skip connections\n",
    "- Residual blocks (Conv2d ‚Üí BatchNorm ‚Üí ReLU ‚Üí Conv2d ‚Üí BatchNorm + skip connection)\n",
    "- MaxPool2d downsampling (encoder) and ConvTranspose2d upsampling (decoder)\n",
    "\n",
    "**Key Innovations:**\n",
    "\n",
    "1. **Residual Connections:**\n",
    "   - Identity shortcuts in every encoder/decoder block\n",
    "   - Improved gradient flow for deeper networks\n",
    "   - Prevents degradation in network training\n",
    "\n",
    "2. **Squeeze-and-Excitation (SE) Blocks:**\n",
    "   - Channel-wise attention mechanism (reduction ratio: 16)\n",
    "   - Applied after each residual block and on skip connections\n",
    "   - Learns to emphasize informative features and suppress less useful ones\n",
    "   - Global average pooling ‚Üí FC layers ‚Üí sigmoid gating\n",
    "\n",
    "**Output:**\n",
    "- Sigmoid activation applied in model (outputs probabilities [0, 1])\n",
    "- Compatible with DiceBCELoss for balanced optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b6d25",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### Kaggle Configuration\n",
    "\n",
    "**Dataset:** `fhs-residual-se-unet` (must be added to notebook)\n",
    "\n",
    "**Directory Structure:**\n",
    "- **Project Root:** `/kaggle/input/fhs-residual-se-unet/` (read-only)\n",
    "- **Outputs:** `/kaggle/working/results/`\n",
    "  - Checkpoints, logs, predictions, and visualizations\n",
    "  - Automatically available for download after training completes\n",
    "\n",
    "**Steps:**\n",
    "1. Verify dataset is attached to notebook\n",
    "2. Install/upgrade dependencies (Albumentations 1.4.0, specific NumPy/SciPy versions)\n",
    "3. Import required modules and verify CUDA availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"[Kaggle Setup]\")\n",
    "\n",
    "# Setup paths for Kaggle\n",
    "project_root = Path('/kaggle/input/fhs-residual-se-unet')\n",
    "output_root = Path('/kaggle/working')\n",
    "cache_root = output_root / 'cache'\n",
    "\n",
    "# Verify dataset exists\n",
    "if not project_root.exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Dataset not found at {project_root}\\n\"\n",
    "        f\"Please add the 'fhs-residual-se-unet' dataset to your Kaggle notebook.\"\n",
    "    )\n",
    "\n",
    "if not (project_root / 'accuracy_focus').exists():\n",
    "    raise RuntimeError(\n",
    "        f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "        f\"Please ensure your dataset structure is correct.\"\n",
    "    )\n",
    "\n",
    "print(f\"Project root: {project_root} (read-only)\")\n",
    "print(f\"Output root: {output_root} (writable)\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"\\n‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Kaggle\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# This ensures override Kaggle's pre-installed packages\n",
    "!pip install --force-reinstall --no-cache-dir -q \\\n",
    "    \"numpy==1.26.4\" \\\n",
    "    \"scipy==1.11.4\" \\\n",
    "    \"scikit-learn==1.5.1\" \\\n",
    "    \"albumentations==1.4.0\" \\\n",
    "    \"opencv-python-headless==4.9.0.80\" \\\n",
    "    \"PyYAML>=5.4\" \\\n",
    "    \"tqdm>=4.62\"\n",
    "\n",
    "print(\"\\n‚úì Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import from project structure\n",
    "from accuracy_focus.improved_unet.src.models.residual_se_unet.residual_se_unet_model import ResidualSEUNet\n",
    "from accuracy_focus.standard_unet.src.losses import DiceBCELoss\n",
    "from shared.src.data import HC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "from shared.src.utils.transforms import get_transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de8aea",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae51f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration (use improved_unet config as template)\n",
    "config_path = project_root / 'accuracy_focus' / 'improved_unet' / 'configs' / 'residual_se_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Adjust output paths for Kaggle environment\n",
    "print(f\"Adjusting paths for Kaggle environment...\")\n",
    "config['logging']['checkpoint_dir'] = str(output_root / 'results' / 'checkpoints')\n",
    "config['logging']['log_dir'] = str(output_root / 'results' / 'logs')\n",
    "config['logging']['prediction_dir'] = str(output_root / 'results' / 'predictions')\n",
    "config['logging']['visualization_dir'] = str(output_root / 'results' / 'visualizations')\n",
    "\n",
    "print(f\"  Outputs will be saved to: {output_root / 'results'}\")\n",
    "\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE Reduction Ratio: {config['model']['reduction_ratio']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69934bd",
   "metadata": {},
   "source": [
    "## 3. Model Initialization\n",
    "\n",
    "### Residual SE U-Net Architecture Details\n",
    "\n",
    "**Encoder Path:**\n",
    "- 4 downsampling blocks: 64 ‚Üí 128 ‚Üí 256 ‚Üí 512 filters\n",
    "- Each block: ResidualBlockSE (Conv2d + BN + ReLU + Conv2d + BN + skip) + SE\n",
    "- Downsampling: MaxPool2d (2√ó2, stride=2)\n",
    "\n",
    "**Bottleneck:**\n",
    "- ResidualBlockSE with 1024 filters\n",
    "- Captures highest-level semantic features with channel attention\n",
    "\n",
    "**Decoder Path:**\n",
    "- 4 upsampling blocks: 512 ‚Üí 256 ‚Üí 128 ‚Üí 64 filters\n",
    "- Upsampling: ConvTranspose2d (2√ó2, stride=2)\n",
    "- Each block: ResidualBlockSE √ó 1 after skip connection concatenation\n",
    "\n",
    "**Squeeze-and-Excitation (SE) Mechanism:**\n",
    "- **Applied to:** Each residual block output + skip connections\n",
    "- **Operation:** GlobalAvgPool ‚Üí FC (reduce) ‚Üí ReLU ‚Üí FC (expand) ‚Üí Sigmoid\n",
    "- **Reduction ratio:** 16 (e.g., 512 channels ‚Üí 32 ‚Üí 512)\n",
    "- **Purpose:** Recalibrate channel-wise feature responses adaptively\n",
    "\n",
    "**Residual Connections:**\n",
    "- Identity mappings in all encoder/decoder blocks\n",
    "- Enables training of very deep networks (50+ layers possible)\n",
    "- Gradient flows directly through shortcuts\n",
    "\n",
    "**Output Layer:**\n",
    "- Conv2d (1√ó1) to single channel\n",
    "- **Sigmoid activation applied** ‚Üí outputs probabilities [0, 1]\n",
    "- Compatible with DiceBCELoss for hybrid optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ead4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ResidualSEUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_channels=config['model']['base_filters'],\n",
    "    reduction_ratio=config['model']['reduction_ratio']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "from accuracy_focus.improved_unet.src.models.residual_se_unet.residual_se_unet_model import count_parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nResidual SE U-Net Architecture:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: ~{total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE reduction ratio: {config['model']['reduction_ratio']}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad875143",
   "metadata": {},
   "source": [
    "## 4. Loss Function and Optimization\n",
    "\n",
    "### Loss Function: DiceBCELoss\n",
    "\n",
    "**Hybrid Loss Design:**\n",
    "- **Dice Loss (80%):** Optimizes region overlap (DSC metric)\n",
    "- **BCE Loss (20%):** Optimizes pixel-wise classification\n",
    "\n",
    "**Why Hybrid Loss?**\n",
    "- **Dice component:** Handles extreme class imbalance (2-10% foreground pixels typical)\n",
    "- **BCE component:** Provides pixel-level gradient signals for sharp boundaries\n",
    "- **Weighted combination:** Balances global structure (Dice) with local details (BCE)\n",
    "\n",
    "**Expected input:**\n",
    "- Model outputs probabilities [0, 1] (sigmoid already applied)\n",
    "- Targets are binary masks {0, 1}\n",
    "\n",
    "### Optimizer: Adam\n",
    "- Adaptive learning rate per parameter (lr=1e-3)\n",
    "- Momentum terms: betas=(0.9, 0.999)\n",
    "- Weight decay: Configurable L2 regularization\n",
    "\n",
    "### Learning Rate Scheduler: ReduceLROnPlateau\n",
    "- Monitors validation Dice coefficient (mode='max')\n",
    "- Reduces LR by factor=0.1 when performance plateaus\n",
    "- Patience: Number of epochs without improvement before reduction\n",
    "- Minimum LR: Prevents learning rate from becoming too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c729a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (DiceBCELoss - Combined Dice + BCE)\n",
    "loss_config = config['loss']\n",
    "dice_weight_config = loss_config.get('dice_weight', 0.8)\n",
    "bce_weight_config = loss_config.get('bce_weight', 0.2)\n",
    "smooth_config = loss_config.get('smooth', 1.0e-6)\n",
    "\n",
    "criterion = DiceBCELoss(\n",
    "    dice_weight=dice_weight_config,\n",
    "    bce_weight=bce_weight_config,\n",
    "    smooth=smooth_config\n",
    ")\n",
    "print(f\"Loss Function: {loss_config['name']}\")\n",
    "print(f\"  Dice weight: {dice_weight_config}\")\n",
    "print(f\"  BCE weight: {bce_weight_config}\")\n",
    "print(f\"  Smooth parameter: {smooth_config}\")\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"\\nOptimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"\\nScheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855601c6",
   "metadata": {},
   "source": [
    "## 5. Dataset and Data Loaders\n",
    "\n",
    "### Dataset: HC18 Grand Challenge\n",
    "- **Source:** Fetal head circumference ultrasound images\n",
    "- **Split:** Training / Validation / Test sets\n",
    "- **Image size:** 256√ó256 pixels (grayscale)\n",
    "- **Normalization:** Division by 255.0 ‚Üí [0, 1] range\n",
    "\n",
    "### Data Augmentation Strategy\n",
    "\n",
    "**Training Augmentations (applied on-the-fly):**\n",
    "- **HorizontalFlip** (p=0.5): Mirror symmetry\n",
    "- **VerticalFlip** (p=0.5): Additional spatial variation\n",
    "- **Rotation** (¬±20¬∞, p=0.5): Orientation invariance\n",
    "- **ShiftScaleRotate** (p=0.5):\n",
    "  - Translation: ¬±10% (shift_limit=0.1)\n",
    "  - Scaling: ¬±10% (scale_limit=0.1)\n",
    "  - Combined transformations\n",
    "\n",
    "**Validation/Test:** Preprocessing only (resize + normalize)\n",
    "\n",
    "**Implementation:**\n",
    "- Dynamic augmentation: New variations generated each epoch\n",
    "- Synchronized transforms: Image-mask pairs augmented identically\n",
    "- Library: Albumentations (highly optimized)\n",
    "\n",
    "**DataLoader Configuration:**\n",
    "- Batch size: From config (typically 8-16)\n",
    "- num_workers: 0 (Kaggle compatibility, avoids multiprocessing issues)\n",
    "- pin_memory: True (faster GPU transfer)\n",
    "- Shuffle: True (training only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Helper to build paths\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"Creating augmentation transforms...\")\n",
    "train_transform = get_transforms(height=256, width=256, is_train=True)\n",
    "val_transform = get_transforms(height=256, width=256, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Create datasets - using HC18Dataset for on-the-fly augmentation\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "print(\"Creating test dataset...\")\n",
    "test_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['test_images']),\n",
    "    mask_dir=get_path(data_config['test_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Use num_workers=0 for Kaggle to avoid multiprocessing issues\n",
    "num_workers = 0\n",
    "print(f\"\\nDataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} (disabled for Kaggle)\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Train augmentation: ENABLED (on-the-fly)\")\n",
    "print(f\"  Val/Test augmentation: DISABLED\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a15a70",
   "metadata": {},
   "source": [
    "## 6. Data Validation\n",
    "\n",
    "### Pre-Training Checks\n",
    "\n",
    "Verify data integrity before training:\n",
    "1. **Batch shapes:** Ensure correct tensor dimensions\n",
    "2. **Value ranges:** Images [0, 1], masks {0, 1}\n",
    "3. **Mask binarization:** Confirm masks are strictly binary\n",
    "4. **Foreground ratio:** Check if ~2-10% (typical for fetal head)\n",
    "5. **Visual inspection:** Display sample augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "print(f\"  Mask unique values: {torch.unique(sample_masks)}\")\n",
    "print(f\"  Mask mean (% foreground): {sample_masks.mean():.4f}\")\n",
    "\n",
    "# CRITICAL CHECK: Ensure masks are binary {0, 1}\n",
    "if not torch.all((sample_masks == 0) | (sample_masks == 1)):\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Masks are not binary! Check preprocessing.\")\n",
    "else:\n",
    "    print(\"\\n‚úì Masks are properly binary {0, 1}\")\n",
    "\n",
    "# Check if masks have reasonable foreground ratio (2-10% typical for fetal head)\n",
    "fg_ratio = sample_masks.mean().item()\n",
    "if fg_ratio < 0.01 or fg_ratio > 0.3:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Unusual foreground ratio: {fg_ratio:.2%} (expected 2-10%)\")\n",
    "else:\n",
    "    print(f\"‚úì Foreground ratio looks reasonable: {fg_ratio:.2%}\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd169ded",
   "metadata": {},
   "source": [
    "## 7. Training and Validation Functions\n",
    "\n",
    "### Training Loop (per epoch)\n",
    "1. Set model to training mode\n",
    "2. Iterate through batches with progress bar\n",
    "3. Forward pass: model(images) ‚Üí predictions\n",
    "4. Compute loss: DiceBCELoss(predictions, masks)\n",
    "5. Backward pass + optimizer step\n",
    "6. Track running loss statistics\n",
    "\n",
    "### Validation Loop (per epoch)\n",
    "1. Set model to evaluation mode\n",
    "2. Disable gradient computation (torch.no_grad)\n",
    "3. Forward pass on validation set\n",
    "4. Compute loss and metrics:\n",
    "   - **Dice Coefficient (DSC):** Primary metric\n",
    "   - **IoU Score:** Intersection over Union\n",
    "   - **Pixel Accuracy:** Overall correctness\n",
    "5. Return average metrics across all samples\n",
    "\n",
    "### Early Stopping Strategy\n",
    "- Monitor validation Dice coefficient\n",
    "- Save best model checkpoint when Dice improves\n",
    "- Stop training if no improvement for `patience` epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77524599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f2835",
   "metadata": {},
   "source": [
    "## 8. Training Execution\n",
    "\n",
    "### Training Configuration\n",
    "- **Epochs:** From config (typically 50-100)\n",
    "- **Early stopping:** Patience for convergence\n",
    "- **Checkpoint saving:** Best model based on validation Dice\n",
    "- **Learning rate scheduling:** Automatic reduction on plateau\n",
    "\n",
    "### Monitored Metrics\n",
    "- **Train Loss:** DiceBCELoss on training set\n",
    "- **Val Loss:** DiceBCELoss on validation set\n",
    "- **Val Dice:** Primary evaluation metric (DSC)\n",
    "- **Val IoU:** Intersection over Union score\n",
    "- **Val PA:** Pixel accuracy\n",
    "- **Learning Rate:** Current optimizer learning rate\n",
    "\n",
    "### Training Progress Indicators\n",
    "- üèÜ New best model saved\n",
    "- ‚¨áÔ∏è Learning rate reduced\n",
    "- ‚ö†Ô∏è No improvement warning\n",
    "- ‚õî Early stopping triggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - Residual SE U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    dice_indicator = ' üèÜ' if val_dice > best_dice else ''\n",
    "    lr_change = f' ‚¨áÔ∏è (reduced from {old_lr:.6f})' if current_lr < old_lr else ''\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "    print(f\"Val mIoU: {val_iou:.4f} | Val mPA: {val_pa:.4f}\")\n",
    "    print(f\"LR: {current_lr:.6f}{lr_change}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model_residual_se_unet_v2.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  ‚Üí Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  ‚ö†Ô∏è  No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚õî EARLY STOPPING TRIGGERED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Stopped at epoch: {epoch+1}\")\n",
    "        print(f\"  Best Dice Score:  {best_dice:.4f}\")\n",
    "        print(f\"  Patience limit:   {patience} epochs without improvement\")\n",
    "        print(f\"{'='*70}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b603ff",
   "metadata": {},
   "source": [
    "## 9. Training Visualization\n",
    "\n",
    "### Learning Curves\n",
    "\n",
    "**Plot 1 - Loss Curves:**\n",
    "- Train vs Validation loss over epochs\n",
    "- Monitors overfitting (divergence between curves)\n",
    "\n",
    "**Plot 2 - Dice Coefficient:**\n",
    "- Validation Dice over epochs\n",
    "- Horizontal line marks best performance\n",
    "\n",
    "**Plot 3 - IoU Score:**\n",
    "- Validation IoU over epochs\n",
    "- Secondary segmentation quality metric\n",
    "\n",
    "**Plot 4 - Learning Rate Schedule:**\n",
    "- Learning rate evolution (log scale)\n",
    "- Shows ReduceLROnPlateau reductions\n",
    "\n",
    "**Saved to:** `/kaggle/working/results/logs/training_curves.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice + BCE)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c084a0",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation and Visualization\n",
    "\n",
    "### Evaluation Process\n",
    "1. Load best checkpoint (highest validation Dice)\n",
    "2. Run inference on test set\n",
    "3. Apply threshold (0.5) to probabilities\n",
    "4. Compute per-sample metrics (Dice, IoU, PA)\n",
    "5. Visualize predictions with ground truth\n",
    "\n",
    "### Prediction Visualization\n",
    "- **Column 1:** Input ultrasound image\n",
    "- **Column 2:** Ground truth segmentation mask\n",
    "- **Column 3:** Model prediction with metrics overlay\n",
    "\n",
    "**Saved to:** `/kaggle/working/results/predictions/sample_predictions.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model_residual_se_unet_v2.pth'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get validation samples\n",
    "test_images, test_masks = next(iter(test_loader))\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    test_probs = model(test_images)\n",
    "    test_preds = (test_probs > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(test_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = test_images[i, 0].cpu().numpy()\n",
    "    mask = test_masks[i, 0].numpy()\n",
    "    pred = test_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample (ensure both tensors on same device)\n",
    "    pred_tensor = test_preds[i].cpu()\n",
    "    mask_tensor = test_masks[i].to(pred_tensor.device)\n",
    "    dice = dice_coefficient(pred_tensor, mask_tensor).item()\n",
    "    iou = iou_score(pred_tensor, mask_tensor).item()\n",
    "    pa = pixel_accuracy(pred_tensor, mask_tensor)\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f} | PA: {pa:.4f}', \n",
    "                         fontsize=10, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(test_images[:4].cpu(), test_masks[:4], test_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58573c0b",
   "metadata": {},
   "source": [
    "## 11. Experiment Summary\n",
    "\n",
    "### Model Architecture: Residual SE U-Net\n",
    "\n",
    "**Key Components:**\n",
    "1. **Residual Blocks:** Identity shortcuts for improved gradient flow\n",
    "2. **SE Blocks:** Channel-wise attention (reduction ratio 16)\n",
    "3. **Skip Connections:** Encoder features with SE recalibration\n",
    "4. **Activation:** ReLU (hidden layers), Sigmoid (output)\n",
    "5. **Normalization:** BatchNorm after each convolution\n",
    "\n",
    "**Model Specifications:**\n",
    "- Input: 1-channel grayscale (256√ó256)\n",
    "- Output: 1-channel probability map [0, 1]\n",
    "- Base filters: 64\n",
    "- Depth: 5 levels (4 encoder + bottleneck)\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "**Loss Function:** DiceBCELoss (0.8 Dice + 0.2 BCE)\n",
    "- Combines region overlap optimization with pixel-wise supervision\n",
    "- Handles class imbalance effectively\n",
    "\n",
    "**Optimizer:** Adam\n",
    "- Learning rate: 1e-3\n",
    "- Weight decay: Configurable L2 regularization\n",
    "\n",
    "**Data Augmentation:**\n",
    "- Horizontal/Vertical flip, Rotation (¬±20¬∞)\n",
    "- ShiftScaleRotate (¬±10% translation/scale)\n",
    "\n",
    "### Why Residual SE U-Net?\n",
    "\n",
    "**Advantages over Standard U-Net:**\n",
    "1. **Residual connections:** Deeper networks without degradation\n",
    "2. **Channel attention:** Automatic feature recalibration\n",
    "3. **Better gradient flow:** Faster convergence, higher accuracy\n",
    "4. **Feature reuse:** More efficient parameter usage\n",
    "\n",
    "**Comparison to Attention U-Net:**\n",
    "- **Attention U-Net:** Spatial attention on skip connections\n",
    "- **Residual SE U-Net:** Channel attention everywhere + residual learning\n",
    "- **Trade-off:** More parameters, potentially better feature learning\n",
    "\n",
    "### Expected Performance\n",
    "\n",
    "**Target Metrics:**\n",
    "- **Dice Coefficient:** >97.5%\n",
    "- **IoU Score:** >95.0%\n",
    "- **Pixel Accuracy:** >99.0%\n",
    "\n",
    "---\n",
    "\n",
    "### Kaggle-Specific Notes\n",
    "\n",
    "**Output Locations:**\n",
    "- Checkpoints: `/kaggle/working/results/checkpoints/`\n",
    "- Logs: `/kaggle/working/results/logs/`\n",
    "- Predictions: `/kaggle/working/results/predictions/`\n",
    "- Visualizations: `/kaggle/working/results/visualizations/`\n",
    "\n",
    "**Download Results:**\n",
    "All outputs automatically available in Kaggle's output tab after notebook finishes execution.\n",
    "\n",
    "**GPU Usage:**\n",
    "Enable GPU acceleration in Kaggle notebook settings for optimal training speed (~10-20 min per epoch with GPU vs hours on CPU)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
