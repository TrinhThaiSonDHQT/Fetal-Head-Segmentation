{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8de5bb",
   "metadata": {},
   "source": [
    "# ASPP-Enhanced Residual SE U-Net for Fetal Head Segmentation\n",
    "## Training Notebook (Google Colab Compatible)\n",
    "\n",
    "**Platform:** Google Colab with GPU acceleration\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "This notebook implements an **ASPP-Enhanced Residual SE U-Net** for medical image segmentation with:\n",
    "\n",
    "**Core Architecture:**\n",
    "- U-Net encoder-decoder with residual connections and squeeze-and-excitation (SE) blocks\n",
    "- ResidualBlockSE in encoder/decoder (two 3×3 convs + BatchNorm + ReLU + SE + skip connection)\n",
    "- MaxPool2d downsampling (encoder) and ConvTranspose2d upsampling (decoder)\n",
    "\n",
    "**Key Innovations:**\n",
    "\n",
    "1. **ASPP Module at Bottleneck**: Multi-scale contextual feature extraction\n",
    "   - 1×1 convolution (point-wise features)\n",
    "   - 3×3 atrous convolutions with dilation rates [6, 12, 18]\n",
    "   - Global average pooling branch (image-level features)\n",
    "   - Captures features at different scales simultaneously\n",
    "\n",
    "2. **Squeeze-and-Excitation (SE) Blocks**: Channel-wise attention mechanism\n",
    "   - Applied after every ResidualBlockSE\n",
    "   - Applied to skip connections before concatenation with decoder\n",
    "   - Learns to emphasize informative channels and suppress less useful ones\n",
    "   - Reduction ratio: 16\n",
    "\n",
    "3. **Residual Connections**: Skip connections within blocks for better gradient flow\n",
    "\n",
    "**Output:**\n",
    "- Sigmoid activation for binary segmentation probabilities [0, 1]\n",
    "- Compatible with DiceBCELoss (combined Dice + BCE loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf26ad",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "### Google Colab Configuration\n",
    "\n",
    "**Repository:** `https://github.com/TrinhThaiSonDHQT/Fetal-Head-Segmentation`\n",
    "\n",
    "**Directory Structure:**\n",
    "- **Project Root:** `/content/Fetal-Head-Segmentation/`\n",
    "- **Outputs:** `/content/outputs/results/`\n",
    "  - Checkpoints, logs, predictions, and visualizations\n",
    "  - Download results after training completes\n",
    "\n",
    "**Steps:**\n",
    "1. Clone repository from GitHub\n",
    "2. Install dependencies (Albumentations 1.3.1)\n",
    "3. Import required modules and verify CUDA availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository\n",
    "import os\n",
    "\n",
    "# Check if already cloned\n",
    "if not os.path.exists('/content/Fetal-Head-Segmentation'):\n",
    "    print(\"Cloning repository from GitHub...\")\n",
    "    !git clone https://github.com/TrinhThaiSonDHQT/Fetal-Head-Segmentation.git\n",
    "    print(\"✓ Repository cloned successfully\")\n",
    "else:\n",
    "    print(\"✓ Repository already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"[Google Colab Setup]\")\n",
    "\n",
    "# Setup paths for Google Colab\n",
    "project_root = Path('/content/Fetal-Head-Segmentation')\n",
    "output_root = Path('/content/outputs')\n",
    "cache_root = output_root / 'cache'\n",
    "\n",
    "# Verify project exists\n",
    "if not project_root.exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Project not found at {project_root}\\n\"\n",
    "        f\"Please run the previous cell to clone the repository from GitHub.\"\n",
    "    )\n",
    "\n",
    "if not (project_root / 'accuracy_focus').exists():\n",
    "    raise RuntimeError(\n",
    "        f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "        f\"Please ensure the repository was cloned correctly.\"\n",
    "    )\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Output root: {output_root}\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"\\n✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "print(\"Installing required packages...\")\n",
    "\n",
    "# Colab has most packages pre-installed (PyTorch, NumPy, Matplotlib, OpenCV)\n",
    "# Pin Albumentations to 1.3.1 for compatibility with both Colab and Kaggle\n",
    "!pip install -q albumentations==1.3.1\n",
    "\n",
    "print(\"\\n✓ Packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7de075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from accuracy_focus.standard_unet.src.losses import DiceBCELoss\n",
    "from accuracy_focus.improved_unet.src.models.aspp_residual_se_unet.aspp_residual_se_unet_model import ASPPResidualSEUNet, count_parameters\n",
    "\n",
    "from shared.src.data import HC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "from shared.src.utils.transforms import get_transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93459378",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration (use improved_unet config as template)\n",
    "config_path = project_root / 'accuracy_focus' / 'improved_unet' / 'configs' / 'improved_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update model name and parameters for ASPP-Enhanced Residual SE U-Net\n",
    "config['model']['name'] = 'ASPPResidualSEUNet'\n",
    "config['model']['reduction_ratio'] = 16  # SE block reduction ratio\n",
    "config['model']['atrous_rates'] = [6, 12, 18]  # ASPP dilation rates\n",
    "config['model']['aspp_dropout'] = 0.5  # ASPP dropout rate\n",
    "\n",
    "# Adjust output paths for Google Colab environment\n",
    "print(f\"Adjusting paths for Google Colab environment...\")\n",
    "config['logging']['checkpoint_dir'] = str(output_root / 'results' / 'checkpoints')\n",
    "config['logging']['log_dir'] = str(output_root / 'results' / 'logs')\n",
    "config['logging']['prediction_dir'] = str(output_root / 'results' / 'predictions')\n",
    "config['logging']['visualization_dir'] = str(output_root / 'results' / 'visualizations')\n",
    "\n",
    "print(f\"  Outputs will be saved to: {output_root / 'results'}\")\n",
    "\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE Reduction Ratio: {config['model']['reduction_ratio']}\")\n",
    "print(f\"  ASPP Atrous Rates: {config['model']['atrous_rates']}\")\n",
    "print(f\"  ASPP Dropout: {config['model']['aspp_dropout']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3423668",
   "metadata": {},
   "source": [
    "## 3. Model Initialization\n",
    "\n",
    "### ASPP-Enhanced Residual SE U-Net Architecture Details\n",
    "\n",
    "**Encoder Path:**\n",
    "- 4 downsampling blocks: 64 → 128 → 256 → 512 filters\n",
    "- Each block: ResidualBlockSE (Conv2d + BatchNorm + ReLU) × 2 + SE block + residual skip\n",
    "- Downsampling: MaxPool2d (2×2, stride=2)\n",
    "- SE blocks provide channel-wise attention\n",
    "\n",
    "**Bottleneck (ASPP Module):**\n",
    "- Multi-scale feature extraction with 1024 total filters\n",
    "- **1×1 convolution**: Point-wise features\n",
    "- **3×3 atrous convolutions**: Dilation rates [6, 12, 18] for multi-scale context\n",
    "- **Global Average Pooling**: Image-level features\n",
    "- **Dropout (0.5)**: Regularization to prevent overfitting\n",
    "- **Fusion**: Concatenate all branches and project to 1024 channels\n",
    "\n",
    "**Decoder Path:**\n",
    "- 4 upsampling blocks: 512 → 256 → 128 → 64 filters\n",
    "- Upsampling: ConvTranspose2d (2×2, stride=2)\n",
    "- Skip connections: SE-enhanced encoder features concatenated with decoder\n",
    "- Each block: ResidualBlockSE × 2 after concatenation\n",
    "\n",
    "**Channel Attention (SE Blocks):**\n",
    "- Applied after every ResidualBlockSE in encoder/decoder\n",
    "- Applied to skip connections before concatenation\n",
    "- Squeeze: Global average pooling\n",
    "- Excitation: FC → ReLU → FC → Sigmoid\n",
    "- Reduction ratio: 16 (balances performance vs. parameters)\n",
    "\n",
    "**Output Layer:**\n",
    "- Conv2d (1×1) to single channel\n",
    "- **Sigmoid activation** → outputs probabilities [0, 1]\n",
    "- Compatible with DiceBCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef60416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize ASPP-Enhanced Residual SE U-Net\n",
    "model = ASPPResidualSEUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_channels=config['model']['base_filters'],\n",
    "    reduction_ratio=config['model']['reduction_ratio'],\n",
    "    atrous_rates=config['model']['atrous_rates'],\n",
    "    aspp_dropout=config['model']['aspp_dropout']\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nASPP-Enhanced Residual SE U-Net Architecture:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: ~{total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE reduction ratio: {config['model']['reduction_ratio']}\")\n",
    "print(f\"  ASPP atrous rates: {config['model']['atrous_rates']}\")\n",
    "print(f\"  ASPP dropout: {config['model']['aspp_dropout']}\")\n",
    "print(f\"  Output activation: Sigmoid\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")\n",
    "print(f\"  Output type: Probabilities (sigmoid activated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed3aa7",
   "metadata": {},
   "source": [
    "## 4. Loss Function and Optimization\n",
    "\n",
    "### Loss Function: DiceBCELoss\n",
    "\n",
    "**Hybrid Loss Design:**\n",
    "- **Dice Loss (80%):** Optimizes region overlap (DSC metric)\n",
    "  - Handles class imbalance naturally\n",
    "  - Directly optimizes the evaluation metric\n",
    "- **BCE Loss (20%):** Optimizes pixel-wise classification\n",
    "  - Provides stable gradients\n",
    "  - Handles boundary refinement\n",
    "\n",
    "**Key Features:**\n",
    "- Expects **probabilities** [0, 1] as input (model outputs sigmoid)\n",
    "- Smooth parameter (1.0) for numerical stability in Dice calculation\n",
    "\n",
    "### Optimizer: Adam\n",
    "- Adaptive learning rate per parameter\n",
    "- Learning rate: 1e-3 (configurable)\n",
    "- Weight decay: 1e-4 (L2 regularization)\n",
    "\n",
    "### Learning Rate Scheduler: ReduceLROnPlateau\n",
    "- Monitors validation Dice coefficient\n",
    "- Reduces LR by factor of 0.5 when validation plateaus\n",
    "- Patience: 5 epochs\n",
    "- Minimum LR: 1e-6\n",
    "- Helps fine-tune convergence and escape local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_config = config['loss']\n",
    "dice_weight_config = loss_config.get('dice_weight', 0.8)\n",
    "bce_weight_config = loss_config.get('bce_weight', 0.2)\n",
    "smooth_config = loss_config.get('smooth', 1.0)\n",
    "\n",
    "# Use DiceBCELoss\n",
    "criterion = DiceBCELoss(\n",
    "    dice_weight=dice_weight_config,\n",
    "    bce_weight=bce_weight_config,\n",
    "    smooth=smooth_config\n",
    ")\n",
    "\n",
    "print(f\"Loss Function: DiceBCELoss\")\n",
    "print(f\"  Dice weight: {dice_weight_config}\")\n",
    "print(f\"  BCE weight: {bce_weight_config}\")\n",
    "print(f\"  Smooth parameter: {smooth_config}\")\n",
    "\n",
    "# Optimizer (Adam)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"\\nOptimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "print(f\"  Weight decay: {optimizer_config['weight_decay']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"\\nScheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")\n",
    "print(f\"  Min LR: {scheduler_config['min_lr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490a309",
   "metadata": {},
   "source": [
    "## 5. Data Loading and Augmentation\n",
    "\n",
    "### Preprocessing Pipeline (All Images)\n",
    "\n",
    "Applied consistently to training, validation, and test sets:\n",
    "1. **Normalization:** Divide pixel values by 255.0 → [0, 1] range\n",
    "2. **Resizing:** 256×256 pixels (maintains aspect ratio consistency)\n",
    "3. **Tensor Conversion:** NumPy array → PyTorch tensor (C×H×W format)\n",
    "\n",
    "### Data Augmentation (Training Only)\n",
    "\n",
    "**On-the-fly augmentation** using Albumentations library:\n",
    "- **HorizontalFlip:** p=0.5 (mirrors left-right)\n",
    "- **VerticalFlip:** p=0.5 (mirrors top-bottom)\n",
    "- **Rotation:** ±20° with p=0.5 (handles probe orientation variations)\n",
    "- **ShiftScaleRotate:** p=0.5\n",
    "  - Translation: ±10% (handles positioning variations)\n",
    "  - Scaling: ±10% (handles zoom variations)\n",
    "\n",
    "**Benefits:**\n",
    "- Augmentation applied **per epoch** → different samples each time\n",
    "- Improves model generalization and robustness\n",
    "- Prevents overfitting on small datasets\n",
    "- Image-mask transforms synchronized automatically\n",
    "\n",
    "**Validation/Test:**\n",
    "- **No augmentation** applied\n",
    "- Only preprocessing (normalize, resize, tensorize)\n",
    "- Ensures consistent evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f51a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Helper to build paths\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"Creating augmentation transforms...\")\n",
    "train_transform = get_transforms(height=256, width=256, is_train=True)\n",
    "val_transform = get_transforms(height=256, width=256, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, VerticalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Create datasets - using HC18Dataset for on-the-fly augmentation\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "print(\"Creating test dataset...\")\n",
    "test_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['test_images']),\n",
    "    mask_dir=get_path(data_config['test_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Use num_workers=0 for Google Colab to avoid multiprocessing issues\n",
    "num_workers = 0\n",
    "print(f\"\\nDataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} (disabled for Google Colab)\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Train augmentation: ENABLED (on-the-fly)\")\n",
    "print(f\"  Val/Test augmentation: DISABLED\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081dcb4",
   "metadata": {},
   "source": [
    "## 6. Data Quality Verification\n",
    "\n",
    "Verify data integrity before training to catch preprocessing errors early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f56d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "print(f\"  Mask unique values: {torch.unique(sample_masks)}\")\n",
    "print(f\"  Mask mean (% foreground): {sample_masks.mean():.4f}\")\n",
    "\n",
    "# CRITICAL CHECK: Ensure masks are binary {0, 1}\n",
    "if not torch.all((sample_masks == 0) | (sample_masks == 1)):\n",
    "    print(\"\\n⚠️  WARNING: Masks are not binary! Check preprocessing.\")\n",
    "else:\n",
    "    print(\"\\n✓ Masks are properly binary {0, 1}\")\n",
    "\n",
    "# Check if masks have reasonable foreground ratio (2-10% typical for fetal head)\n",
    "fg_ratio = sample_masks.mean().item()\n",
    "if fg_ratio < 0.01 or fg_ratio > 0.3:\n",
    "    print(f\"⚠️  WARNING: Unusual foreground ratio: {fg_ratio:.2%} (expected 2-10%)\")\n",
    "else:\n",
    "    print(f\"✓ Foreground ratio looks reasonable: {fg_ratio:.2%}\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a803c",
   "metadata": {},
   "source": [
    "## 7. Training and Validation Functions\n",
    "\n",
    "### train_one_epoch()\n",
    "- Sets model to training mode\n",
    "- Iterates through training batches\n",
    "- Forward pass → loss calculation → backward pass → optimizer step\n",
    "- Returns average epoch loss\n",
    "\n",
    "### validate()\n",
    "- Sets model to evaluation mode (disables dropout, batchnorm updates)\n",
    "- Computes loss and metrics on validation set\n",
    "- Model outputs probabilities [0, 1] (sigmoid activated)\n",
    "- Thresholds at 0.5 for binary predictions\n",
    "- Calculates: Dice coefficient, IoU, Pixel Accuracy\n",
    "- Returns average metrics across all validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            # Model outputs probabilities [0, 1] (sigmoid activated)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c0afb",
   "metadata": {},
   "source": [
    "## 8. Training Loop\n",
    "\n",
    "### Training Configuration\n",
    "- **Epochs:** Configurable (typically 50-100)\n",
    "- **Early Stopping:** Monitors validation Dice coefficient\n",
    "  - Stops if no improvement for N consecutive epochs\n",
    "  - Prevents overfitting and saves compute time\n",
    "- **Model Checkpointing:** Saves best model based on validation Dice\n",
    "\n",
    "### Per-Epoch Workflow\n",
    "1. Train on full training set\n",
    "2. Validate on validation set\n",
    "3. Update learning rate (ReduceLROnPlateau scheduler)\n",
    "4. Log metrics: loss, Dice, IoU, pixel accuracy\n",
    "5. Save model if validation Dice improves\n",
    "6. Check early stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - ASPP-Enhanced Residual SE U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):    \n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    dice_indicator = ' 🏆' if val_dice > best_dice else ''\n",
    "    lr_change = f' ⬇️ (reduced from {old_lr:.6f})' if current_lr < old_lr else ''\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}{dice_indicator}\")\n",
    "    print(f\"Val mIoU: {val_iou:.4f} | Val mPA: {val_pa:.4f}\")\n",
    "    if lr_change: print(f\"LR: {current_lr:.6f}{lr_change}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model_aspp_residual_se_unet.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  → Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  ⚠️  No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"⛔ EARLY STOPPING TRIGGERED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Stopped at epoch: {epoch+1}\")\n",
    "        print(f\"  Best Dice Score:  {best_dice:.4f}\")\n",
    "        print(f\"  Patience limit:   {patience} epochs without improvement\")\n",
    "        print(f\"{'='*70}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b29807",
   "metadata": {},
   "source": [
    "## 9. Training Visualization\n",
    "\n",
    "Generate plots to analyze training dynamics and convergence:\n",
    "- **Loss curves:** Training vs validation loss over epochs\n",
    "- **Dice coefficient:** Validation performance trend\n",
    "- **IoU score:** Intersection over Union metric progression\n",
    "- **Learning rate:** ReduceLROnPlateau schedule adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97005d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice + BCE)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6834e",
   "metadata": {},
   "source": [
    "## 10. Model Inference and Results\n",
    "\n",
    "### Evaluation on Test Set\n",
    "\n",
    "Load the best checkpoint (highest validation Dice) and visualize predictions:\n",
    "- Compare input images, ground truth masks, and model predictions\n",
    "- Calculate per-sample metrics (Dice, IoU, Pixel Accuracy)\n",
    "- Assess segmentation quality visually\n",
    "\n",
    "**Note:** Model outputs probabilities [0, 1] (sigmoid activated), thresholded at 0.5 for binary predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model_aspp_residual_se_unet.pth'\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get test samples\n",
    "test_images, test_masks = next(iter(test_loader))\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    # Model outputs probabilities [0, 1] (sigmoid activated)\n",
    "    test_outputs = model(test_images)\n",
    "    test_preds = (test_outputs > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(test_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = test_images[i, 0].cpu().numpy()\n",
    "    mask = test_masks[i, 0].numpy()\n",
    "    pred = test_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample (ensure both tensors on same device)\n",
    "    pred_tensor = test_preds[i].cpu()\n",
    "    mask_tensor = test_masks[i].to(pred_tensor.device)\n",
    "    dice = dice_coefficient(pred_tensor, mask_tensor).item()\n",
    "    iou = iou_score(pred_tensor, mask_tensor).item()\n",
    "    pa = pixel_accuracy(pred_tensor, mask_tensor)\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f} | PA: {pa:.4f}', \n",
    "                         fontsize=10, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(test_images[:4].cpu(), test_masks[:4], test_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)\n",
    "print(f\"Sample predictions saved to {pred_dir / 'sample_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fedede1",
   "metadata": {},
   "source": [
    "## 11. Download Results (Google Colab)\n",
    "\n",
    "After training completes, download results to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results from Google Colab\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"Creating archive of results...\")\n",
    "\n",
    "# Create zip archive\n",
    "results_dir = output_root / 'results'\n",
    "archive_path = output_root / 'aspp_residual_se_unet_results.zip'\n",
    "\n",
    "# Remove old archive if exists\n",
    "if archive_path.exists():\n",
    "    archive_path.unlink()\n",
    "\n",
    "# Create zip file\n",
    "shutil.make_archive(\n",
    "    str(output_root / 'aspp_residual_se_unet_results'),\n",
    "    'zip',\n",
    "    str(results_dir)\n",
    ")\n",
    "\n",
    "print(f\"✓ Archive created: {archive_path}\")\n",
    "print(f\"Archive size: {archive_path.stat().st_size / (1024**2):.2f} MB\")\n",
    "\n",
    "# Download archive\n",
    "print(\"\\nDownloading archive...\")\n",
    "files.download(str(archive_path))\n",
    "print(\"✓ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd83757",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Key Innovations:\n",
    "\n",
    "1. **ASPP Module at Bottleneck**: Multi-scale feature extraction\n",
    "   - 1×1 convolution for point-wise features\n",
    "   - 3×3 atrous convolutions with dilation rates [6, 12, 18]\n",
    "   - Global average pooling for image-level context\n",
    "   - Captures features at multiple scales simultaneously\n",
    "\n",
    "2. **Residual Blocks with SE**: Two 3×3 convolutions + BatchNorm + ReLU + SE attention + skip connections\n",
    "3. **SE Blocks on Skip Connections**: Channel-wise attention before concatenation\n",
    "4. **Improved Gradient Flow**: Residual connections throughout the network\n",
    "\n",
    "### Architecture Highlights:\n",
    "\n",
    "- **Encoder**: 4 stages with ResidualBlockSE (64→128→256→512)\n",
    "- **Bottleneck**: ASPP module (512→1024 channels, multi-scale context)\n",
    "- **Decoder**: 4 stages with ResidualBlockSE (512→256→128→64)\n",
    "- **Total Parameters**: ~38M parameters (~146 MB)\n",
    "\n",
    "### Training Configuration:\n",
    "\n",
    "- **Loss**: DiceBCELoss (0.8 Dice + 0.2 BCE)\n",
    "- **Optimizer**: Adam (lr=1e-3, weight decay=1e-4)\n",
    "- **Scheduler**: ReduceLROnPlateau (patience=5, factor=0.5)\n",
    "- **Augmentation**: HorizontalFlip, VerticalFlip, Rotation, ShiftScaleRotate (on-the-fly)\n",
    "- **Early Stopping**: Monitors validation Dice (patience=10)\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "The ASPP module should improve segmentation accuracy by capturing multi-scale contextual information, especially useful for:\n",
    "- Objects at varying scales\n",
    "- Better boundary detection\n",
    "- Improved context understanding\n",
    "- Handling size variations in fetal head across different gestational ages\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Compare with Standard U-Net and Residual SE U-Net (without ASPP)\n",
    "2. Analyze performance improvement from ASPP\n",
    "3. Visualize multi-scale features captured by ASPP\n",
    "4. Evaluate on full HC18 test set\n",
    "5. Calculate HD95 metric for boundary accuracy assessment\n",
    "\n",
    "---\n",
    "\n",
    "**Download all results** using the cell above to analyze on your local machine."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
