{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60927af",
   "metadata": {},
   "source": [
    "# ASPP-Enhanced Residual SE U-Net Training Notebook (Universal)\n",
    "## Fetal Head Segmentation in Ultrasound Images\n",
    "\n",
    "**Compatible with:** Google Colab, Kaggle, and Local Jupyter\n",
    "\n",
    "This notebook implements an **ASPP-Enhanced Residual U-Net with Squeeze-and-Excitation (SE)** mechanism with:\n",
    "1. ResidualBlockSE in encoder/decoder (two 3√ó3 convs + SE + skip connection)\n",
    "2. **ASPP module at bottleneck** for multi-scale contextual feature extraction\n",
    "3. SE blocks applied after every encoder/decoder block\n",
    "4. SE blocks applied to skip connections before concatenation\n",
    "5. Improved gradient flow through residual connections\n",
    "6. Channel-wise attention mechanism for better feature learning\n",
    "7. Multi-scale feature capture using atrous convolutions at different dilation rates\n",
    "\n",
    "**Key Innovation:** ASPP (Atrous Spatial Pyramid Pooling) at the bottleneck captures features at multiple scales (dilation rates: 6, 12, 18), improving segmentation accuracy for objects of varying sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbfeab",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "**Environment Detection:**\n",
    "- **Google Colab**: Clones repository from GitHub to `/content/Fetal-Head-Segmentation`\n",
    "- **Kaggle**: Uses `/kaggle/input/fetal-head-segmentation` for read-only data\n",
    "- **Local**: Uses project structure as-is\n",
    "\n",
    "**Output Directories:**\n",
    "- **Google Colab**: `/content/outputs/` (writable, lost after session)\n",
    "- **Kaggle**: `/kaggle/working/` (writable, downloadable)\n",
    "- **Local**: Project structure as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "def detect_environment():\n",
    "    \"\"\"Detect if running on Colab, Kaggle, or locally\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        if os.path.exists('/kaggle/input'):\n",
    "            return 'kaggle'\n",
    "        else:\n",
    "            return 'local'\n",
    "\n",
    "environment = detect_environment()\n",
    "print(f\"Running on: {environment.upper()}\")\n",
    "\n",
    "# Setup paths based on environment\n",
    "if environment == 'colab':\n",
    "    print(\"\\n[Google Colab Setup]\")\n",
    "    \n",
    "    # Clone repository if not already present\n",
    "    repo_path = Path('/content/Fetal-Head-Segmentation')\n",
    "    if not repo_path.exists():\n",
    "        print(\"Cloning repository from GitHub...\")\n",
    "        !git clone https://github.com/TrinhThaiSonDHQT/Fetal-Head-Segmentation.git /content/Fetal-Head-Segmentation\n",
    "        print(\"‚úì Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"‚úì Repository already exists\")\n",
    "    \n",
    "    project_root = repo_path\n",
    "    output_root = Path('/content/outputs')\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"Output root: {output_root}\")\n",
    "    \n",
    "elif environment == 'kaggle':\n",
    "    print(\"\\n[Kaggle Setup]\")\n",
    "    project_root = Path('/kaggle/input/fetal-head-segmentation')\n",
    "    output_root = Path('/kaggle/working')\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    if not project_root.exists():\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset not found at {project_root}\\n\"\n",
    "            f\"Please add the 'fetal-head-segmentation' dataset to your Kaggle notebook.\"\n",
    "        )\n",
    "    \n",
    "    if not (project_root / 'accuracy_focus').exists():\n",
    "        raise RuntimeError(\n",
    "            f\"'accuracy_focus' folder not found in {project_root}\\n\"\n",
    "            f\"Please ensure your dataset structure is correct.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Project root: {project_root} (read-only)\")\n",
    "    print(f\"Output root: {output_root} (writable)\")\n",
    "    \n",
    "else:  # local\n",
    "    print(\"\\n[Local Setup]\")\n",
    "    current = Path(os.getcwd())\n",
    "    project_root = None\n",
    "    \n",
    "    # Find project root\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / 'accuracy_focus').exists():\n",
    "            project_root = parent\n",
    "            break\n",
    "    \n",
    "    if project_root is None:\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot find project root with 'accuracy_focus' folder.\\n\"\n",
    "            f\"Current directory: {os.getcwd()}\"\n",
    "        )\n",
    "    \n",
    "    output_root = project_root / 'accuracy_focus' / 'improved_unet'\n",
    "    cache_root = output_root / 'cache'\n",
    "    \n",
    "    print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"\\n‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (for Colab/Kaggle)\n",
    "if environment in ['colab', 'kaggle']:\n",
    "    print(\"Installing/upgrading required packages...\")\n",
    "    !pip install -q albumentations==1.3.1 opencv-python-headless PyYAML tqdm\n",
    "    print(\"‚úì Packages installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Import from project structure\n",
    "from accuracy_focus.improved_unet.src.models.aspp_residual_se_unet.aspp_residual_se_unet_model import ASPPResidualSEUNet\n",
    "from accuracy_focus.standard_unet.src.losses import DiceLoss, DiceBCELoss\n",
    "from shared.src.data import HC18Dataset\n",
    "from shared.src.metrics.segmentation_metrics import dice_coefficient, iou_score, pixel_accuracy\n",
    "from shared.src.utils.visualization import save_prediction_grid, visualize_sample\n",
    "from shared.src.utils.transforms import get_transforms\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b164f",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration (use improved_unet config as template)\n",
    "config_path = project_root / 'accuracy_focus' / 'improved_unet' / 'configs' / 'improved_unet_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update model name and parameters\n",
    "config['model']['name'] = 'ASPPResidualSEUNet'\n",
    "config['model']['reduction_ratio'] = 16  # SE block reduction ratio\n",
    "config['model']['atrous_rates'] = [6, 12, 18]  # ASPP dilation rates\n",
    "config['model']['aspp_dropout'] = 0.5  # ASPP dropout rate\n",
    "\n",
    "# Adjust output paths based on environment\n",
    "if environment in ['colab', 'kaggle']:\n",
    "    print(f\"Adjusting paths for {environment.upper()} environment...\")\n",
    "    config['logging']['checkpoint_dir'] = str(output_root / 'results' / 'checkpoints')\n",
    "    config['logging']['log_dir'] = str(output_root / 'results' / 'logs')\n",
    "    config['logging']['prediction_dir'] = str(output_root / 'results' / 'predictions')\n",
    "    config['logging']['visualization_dir'] = str(output_root / 'results' / 'visualizations')\n",
    "    \n",
    "    print(f\"  Outputs will be saved to: {output_root / 'results'}\")\n",
    "\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Model: {config['model']['name']}\")\n",
    "print(f\"  Base Filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE Reduction Ratio: {config['model']['reduction_ratio']}\")\n",
    "print(f\"  ASPP Atrous Rates: {config['model']['atrous_rates']}\")\n",
    "print(f\"  ASPP Dropout: {config['model']['aspp_dropout']}\")\n",
    "print(f\"  Learning Rate: {config['training']['optimizer']['lr']}\")\n",
    "print(f\"  Loss Function: {config['loss']['name']}\")\n",
    "print(f\"  Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b8ee2",
   "metadata": {},
   "source": [
    "## 3. Initialize Model\n",
    "\n",
    "The ASPP-Enhanced Residual SE U-Net has:\n",
    "- **Encoder**: 4 downsampling blocks with ResidualBlockSE (64 ‚Üí 128 ‚Üí 256 ‚Üí 512 channels)\n",
    "- **Bottleneck**: **ASPP module** with multi-scale feature extraction (1024 channels)\n",
    "  - 1√ó1 convolution (point-wise features)\n",
    "  - 3√ó3 atrous convolutions with dilation rates [6, 12, 18]\n",
    "  - Global average pooling branch (image-level features)\n",
    "- **Decoder**: 4 upsampling blocks with ResidualBlockSE (512 ‚Üí 256 ‚Üí 128 ‚Üí 64 channels)\n",
    "- **SE Blocks**: Applied after each ResidualBlockSE and on skip connections\n",
    "- **Skip Connections**: SE-enhanced features concatenated with decoder\n",
    "- **Activation**: ReLU in residual blocks, Sigmoid output\n",
    "- **Channel Attention**: SE blocks with reduction ratio 16\n",
    "- **Multi-scale Context**: ASPP captures features at different scales for better segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(config['device'] if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ASPPResidualSEUNet(\n",
    "    in_channels=config['model']['in_channels'],\n",
    "    out_channels=config['model']['out_channels'],\n",
    "    base_channels=config['model']['base_filters'],\n",
    "    reduction_ratio=config['model']['reduction_ratio'],\n",
    "    atrous_rates=config['model']['atrous_rates'],\n",
    "    aspp_dropout=config['model']['aspp_dropout']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "from accuracy_focus.improved_unet.src.models.aspp_residual_se_unet.aspp_residual_se_unet_model import count_parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nASPP-Enhanced Residual SE U-Net Architecture:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: ~{total_params * 4 / (1024**2):.2f} MB (float32)\")\n",
    "print(f\"  Input channels: {config['model']['in_channels']}\")\n",
    "print(f\"  Output channels: {config['model']['out_channels']}\")\n",
    "print(f\"  Base filters: {config['model']['base_filters']}\")\n",
    "print(f\"  SE reduction ratio: {config['model']['reduction_ratio']}\")\n",
    "print(f\"  ASPP atrous rates: {config['model']['atrous_rates']}\")\n",
    "print(f\"  ASPP dropout: {config['model']['aspp_dropout']}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "test_output = model(test_input)\n",
    "print(f\"\\nTest forward pass:\")\n",
    "print(f\"  Input shape: {test_input.shape}\")\n",
    "print(f\"  Output shape: {test_output.shape}\")\n",
    "print(f\"  Output range: [{test_output.min().item():.4f}, {test_output.max().item():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7043d5",
   "metadata": {},
   "source": [
    "## 4. Setup Loss and Optimizer\n",
    "\n",
    "- **Loss**: DiceBCELoss (Combined Dice + BCE with 0.8:0.2 ratio)\n",
    "- **Optimizer**: Adam with learning rate 1e-3\n",
    "- **Scheduler**: ReduceLROnPlateau (monitors validation Dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (DiceBCELoss - Combined Dice + BCE)\n",
    "loss_config = config['loss']\n",
    "criterion = DiceBCELoss(\n",
    "    dice_weight=loss_config.get('dice_weight', 0.8),\n",
    "    bce_weight=loss_config.get('bce_weight', 0.2),\n",
    "    smooth=loss_config.get('smooth', 1.0)\n",
    ")\n",
    "print(f\"Loss Function: {loss_config['name']}\")\n",
    "print(f\"  Dice weight: {loss_config.get('dice_weight', 0.8)}\")\n",
    "print(f\"  BCE weight: {loss_config.get('bce_weight', 0.2)}\")\n",
    "print(f\"  Smooth parameter: {loss_config.get('smooth', 1.0)}\")\n",
    "\n",
    "# Optimizer (Adam with lr=1e-3)\n",
    "optimizer_config = config['training']['optimizer']\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=optimizer_config['lr'],\n",
    "    betas=tuple(optimizer_config['betas']),\n",
    "    eps=optimizer_config['eps'],\n",
    "    weight_decay=optimizer_config['weight_decay']\n",
    ")\n",
    "print(f\"\\nOptimizer: Adam\")\n",
    "print(f\"  Learning rate: {optimizer_config['lr']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler_config = config['training']['scheduler']\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=scheduler_config['mode'],\n",
    "    factor=scheduler_config['factor'],\n",
    "    patience=scheduler_config['patience'],\n",
    "    min_lr=scheduler_config['min_lr']\n",
    ")\n",
    "print(f\"\\nScheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Mode: {scheduler_config['mode']}\")\n",
    "print(f\"  Factor: {scheduler_config['factor']}\")\n",
    "print(f\"  Patience: {scheduler_config['patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b602ff",
   "metadata": {},
   "source": [
    "## 5. Prepare Data Loaders\n",
    "\n",
    "**Preprocessing** (applied to all images):\n",
    "- Images normalized by dividing by 255.0\n",
    "- Resized to 256√ó256 pixels\n",
    "- Converted to PyTorch tensors (C, H, W)\n",
    "\n",
    "**Augmentation** (training only - applied on-the-fly):\n",
    "- Horizontal & Vertical flip (p=0.5)\n",
    "- Rotation (¬±20¬∞, p=0.5)\n",
    "- ShiftScaleRotate: Translation (¬±10%), Scale (¬±10%), p=0.5\n",
    "\n",
    "**Note:** Augmentations are applied dynamically during training. Fresh augmented samples are generated every epoch for better model generalization. Validation uses only preprocessing without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979990e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = config['data']\n",
    "training_config = config['training']\n",
    "\n",
    "# Helper to build paths\n",
    "def get_path(config_path):\n",
    "    \"\"\"Helper to handle both absolute and relative paths\"\"\"\n",
    "    p = Path(config_path)\n",
    "    if p.is_absolute():\n",
    "        return str(p)\n",
    "    else:\n",
    "        return str(project_root / config_path)\n",
    "\n",
    "# Create augmentation transforms\n",
    "print(\"Creating augmentation transforms...\")\n",
    "train_transform = get_transforms(height=256, width=256, is_train=True)\n",
    "val_transform = get_transforms(height=256, width=256, is_train=False)\n",
    "print(\"  Train transform: WITH augmentation (HorizontalFlip, Rotation, ShiftScaleRotate)\")\n",
    "print(\"  Val transform: WITHOUT augmentation (resize + normalize only)\")\n",
    "\n",
    "# Create datasets - using HC18Dataset for on-the-fly augmentation\n",
    "print(\"\\nCreating training dataset...\")\n",
    "train_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['train_images']),\n",
    "    mask_dir=get_path(data_config['train_masks']),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = HC18Dataset(\n",
    "    image_dir=get_path(data_config['val_images']),\n",
    "    mask_dir=get_path(data_config['val_masks']),\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Adjust num_workers for Colab/Kaggle (avoid multiprocessing issues)\n",
    "num_workers = 0 if environment in ['colab', 'kaggle'] else training_config['num_workers']\n",
    "print(f\"\\nDataLoader settings:\")\n",
    "print(f\"  num_workers: {num_workers} ({'disabled for Colab/Kaggle' if num_workers == 0 else 'local multi-threading'})\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=training_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=training_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Datasets Ready:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Train samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {training_config['batch_size']}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Train augmentation: ENABLED (on-the-fly)\")\n",
    "print(f\"  Val augmentation: DISABLED\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27e972",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "\n",
    "print(f\"Sample batch:\")\n",
    "print(f\"  Images shape: {sample_images.shape}\")\n",
    "print(f\"  Masks shape: {sample_masks.shape}\")\n",
    "print(f\"  Image range: [{sample_images.min():.4f}, {sample_images.max():.4f}]\")\n",
    "print(f\"  Mask range: [{sample_masks.min():.4f}, {sample_masks.max():.4f}]\")\n",
    "print(f\"  Mask unique values: {torch.unique(sample_masks)}\")\n",
    "print(f\"  Mask mean (% foreground): {sample_masks.mean():.4f}\")\n",
    "\n",
    "# CRITICAL CHECK: Ensure masks are binary {0, 1}\n",
    "if not torch.all((sample_masks == 0) | (sample_masks == 1)):\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Masks are not binary! Check preprocessing.\")\n",
    "else:\n",
    "    print(\"\\n‚úì Masks are properly binary {0, 1}\")\n",
    "\n",
    "# Check if masks have reasonable foreground ratio (2-10% typical for fetal head)\n",
    "fg_ratio = sample_masks.mean().item()\n",
    "if fg_ratio < 0.01 or fg_ratio > 0.3:\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Unusual foreground ratio: {fg_ratio:.2%} (expected 2-10%)\")\n",
    "else:\n",
    "    print(f\"‚úì Foreground ratio looks reasonable: {fg_ratio:.2%}\")\n",
    "\n",
    "# Visualize first sample\n",
    "visualize_sample(sample_images[0], sample_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16d74a",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
    "    for batch_idx, (images, masks) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    pa_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                dice = dice_coefficient(preds[i], masks[i])\n",
    "                iou = iou_score(preds[i], masks[i])\n",
    "                pa = pixel_accuracy(preds[i], masks[i])\n",
    "                \n",
    "                dice_scores.append(dice.item())\n",
    "                iou_scores.append(iou.item())\n",
    "                pa_scores.append(pa.item())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'dice': f\"{np.mean(dice_scores):.4f}\"\n",
    "            })\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_dice = np.mean(dice_scores)\n",
    "    val_iou = np.mean(iou_scores)\n",
    "    val_pa = np.mean(pa_scores)\n",
    "    \n",
    "    return val_loss, val_dice, val_iou, val_pa\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadfef5f",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92874ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*60}\")\n",
    "print(f\"Starting Training - ASPP-Enhanced Residual SE U-Net\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = config['training']['num_epochs']\n",
    "patience = config['training']['early_stopping_patience']\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_dice': [],\n",
    "    'val_iou': [],\n",
    "    'val_pa': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_dice = 0.0\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Early Stopping Patience: {patience}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_dice, val_iou, val_pa = validate(model, val_loader, criterion, device, epoch)\n",
    "    \n",
    "    # Update learning rate\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_dice)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_pa'].append(val_pa)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    dice_indicator = ' üèÜ' if val_dice > best_dice else ''\n",
    "    lr_change = f' ‚¨áÔ∏è (reduced from {old_lr:.6f})' if current_lr < old_lr else ''\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}{dice_indicator}\")\n",
    "    print(f\"Val mIoU: {val_iou:.4f} | Val mPA: {val_pa:.4f}\")\n",
    "    print(f\"LR: {current_lr:.6f}{lr_change}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    is_best = val_dice > best_dice\n",
    "    if is_best:\n",
    "        best_dice = val_dice\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        checkpoint_dir = Path(get_path(config['logging']['checkpoint_dir']))\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = checkpoint_dir / 'best_model_aspp_residual_se_unet.pth'\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'history': history,\n",
    "            'config': config\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"  ‚Üí Saved best model (Dice: {best_dice:.4f})\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"  ‚ö†Ô∏è  No improvement for {epochs_without_improvement}/{patience} epochs\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚õî EARLY STOPPING TRIGGERED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"  Stopped at epoch: {epoch+1}\")\n",
    "        print(f\"  Best Dice Score:  {best_dice:.4f}\")\n",
    "        print(f\"  Patience limit:   {patience} epochs without improvement\")\n",
    "        print(f\"{'='*70}\")\n",
    "        break\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Best Validation IoU:  {max(history['val_iou']):.4f}\")\n",
    "print(f\"Best Validation PA:   {max(history['val_pa']):.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244960b",
   "metadata": {},
   "source": [
    "## 9. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f848f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (Dice)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Dice coefficient\n",
    "axes[0, 1].plot(history['val_dice'], label='Val Dice', color='green', linewidth=2)\n",
    "axes[0, 1].axhline(y=best_dice, color='red', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[0, 1].set_title('Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(history['val_iou'], label='Val IoU', color='orange', linewidth=2)\n",
    "axes[1, 0].axhline(y=max(history['val_iou']), color='red', linestyle='--', \n",
    "                   label=f\"Best: {max(history['val_iou']):.4f}\")\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[1, 0].set_title('Validation IoU Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(history['lr'], label='Learning Rate', color='red', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "log_dir = Path(get_path(config['logging']['log_dir']))\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(log_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"Training curves saved to {log_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f51ea",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = Path(get_path(config['logging']['checkpoint_dir'])) / 'best_model_aspp_residual_se_unet.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best Dice Score: {checkpoint['best_dice']:.4f}\")\n",
    "\n",
    "# Get validation samples\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "val_images = val_images.to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    val_preds = model(val_images)\n",
    "    val_preds = (val_preds > 0.5).float()\n",
    "\n",
    "# Visualize predictions\n",
    "num_samples = min(4, len(val_images))\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "if num_samples == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Move to CPU and convert to numpy\n",
    "    img = val_images[i, 0].cpu().numpy()\n",
    "    mask = val_masks[i, 0].numpy()\n",
    "    pred = val_preds[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics for this sample\n",
    "    dice = dice_coefficient(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    iou = iou_score(val_preds[i].cpu(), val_masks[i].to(device)).item()\n",
    "    \n",
    "    # Input image\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title('Input Image', fontsize=12, fontweight='bold')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axes[i, 2].imshow(pred, cmap='gray')\n",
    "    axes[i, 2].set_title(f'Prediction\\nDice: {dice:.4f} | IoU: {iou:.4f}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save predictions\n",
    "pred_dir = Path(get_path(config['logging']['prediction_dir']))\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "save_prediction_grid(val_images[:4].cpu(), val_masks[:4], val_preds[:4].cpu(), \n",
    "                    str(pred_dir / 'sample_predictions.png'), num_samples=4)\n",
    "print(f\"Sample predictions saved to {pred_dir / 'sample_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8daaca9",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Innovations:\n",
    "\n",
    "1. **ASPP Module at Bottleneck**: Multi-scale feature extraction using atrous convolutions\n",
    "   - 1√ó1 convolution for point-wise features\n",
    "   - 3√ó3 atrous convolutions with dilation rates [6, 12, 18]\n",
    "   - Global average pooling for image-level context\n",
    "   - Captures features at multiple scales simultaneously\n",
    "\n",
    "2. **Residual Blocks with SE**: Two 3√ó3 convolutions + SE attention + skip connections\n",
    "3. **SE on Skip Connections**: Channel-wise attention before concatenation\n",
    "4. **Improved Gradient Flow**: Residual connections throughout the network\n",
    "\n",
    "### Architecture Highlights:\n",
    "\n",
    "- **Encoder**: 4 stages with ResidualBlockSE (64‚Üí128‚Üí256‚Üí512)\n",
    "- **Bottleneck**: ASPP module (512‚Üí1024 channels, multi-scale context)\n",
    "- **Decoder**: 4 stages with ResidualBlockSE (512‚Üí256‚Üí128‚Üí64)\n",
    "- **Total Parameters**: ~38M parameters (~146 MB)\n",
    "\n",
    "### Training Configuration:\n",
    "\n",
    "- **Loss**: DiceBCELoss (0.8 Dice + 0.2 BCE)\n",
    "- **Optimizer**: Adam (lr=1e-3)\n",
    "- **Scheduler**: ReduceLROnPlateau\n",
    "- **Augmentation**: HorizontalFlip, Rotation, ShiftScaleRotate (on-the-fly)\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "The ASPP module should improve segmentation accuracy by capturing multi-scale contextual information, especially useful for:\n",
    "- Objects at varying scales\n",
    "- Better boundary detection\n",
    "- Improved context understanding\n",
    "\n",
    "### Results:\n",
    "\n",
    "View the training curves and predictions above. Compare with:\n",
    "- **Standard U-Net**: Baseline performance\n",
    "- **Residual SE U-Net**: Improved with residual blocks and attention\n",
    "\n",
    "---\n",
    "\n",
    "### Platform-Specific Notes:\n",
    "\n",
    "**Google Colab:**\n",
    "- Outputs saved to `/content/outputs/results/`\n",
    "- Download: `from google.colab import files; files.download('/content/outputs/results/checkpoints/best_model_aspp_residual_se_unet.pth')`\n",
    "\n",
    "**Kaggle:**\n",
    "- Outputs saved to `/kaggle/working/results/`\n",
    "- Automatically available for download after notebook finishes\n",
    "\n",
    "**Local:**\n",
    "- Outputs saved to `accuracy_focus/improved_unet/results/`\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Compare with Residual SE U-Net (without ASPP)\n",
    "2. Analyze performance improvement from ASPP\n",
    "3. Visualize multi-scale features captured by ASPP\n",
    "4. Test on HC18 test set"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
