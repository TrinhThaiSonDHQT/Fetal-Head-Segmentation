{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30f11dd",
   "metadata": {},
   "source": [
    "# Data Exploration - HC18 Fetal Head Segmentation Dataset\n",
    "\n",
    "This notebook explores the HC18 Grand Challenge dataset for fetal head segmentation.\n",
    "\n",
    "**Dataset Overview:**\n",
    "- Training set: 999 ultrasound images with annotations\n",
    "- Test set: 355 ultrasound images with annotations\n",
    "- Image size: 256×256 pixels (grayscale)\n",
    "- Task: Binary segmentation of fetal head\n",
    "\n",
    "**Sections:**\n",
    "1. Load and inspect dataset statistics\n",
    "2. Visualize sample images and masks\n",
    "3. Analyze image properties\n",
    "4. Visualize data augmentations\n",
    "5. Check pixel size and HC statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0826013",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data import HC18Dataset\n",
    "from src.utils import get_transforms\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ff85a",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "TRAIN_IMG_DIR = '../dataset/training_set/images'\n",
    "TRAIN_MASK_DIR = '../dataset/training_set/masks'\n",
    "TEST_IMG_DIR = '../dataset/test_set/images'\n",
    "TEST_MASK_DIR = '../dataset/test_set/masks'\n",
    "\n",
    "# Count images\n",
    "train_images = sorted(glob(os.path.join(TRAIN_IMG_DIR, '*.png')))\n",
    "train_masks = sorted(glob(os.path.join(TRAIN_MASK_DIR, '*.png')))\n",
    "test_images = sorted(glob(os.path.join(TEST_IMG_DIR, '*.png')))\n",
    "test_masks = sorted(glob(os.path.join(TEST_MASK_DIR, '*.png')))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HC18 DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Images: {len(train_images)}\")\n",
    "print(f\"Training Masks:  {len(train_masks)}\")\n",
    "print(f\"Test Images:     {len(test_images)}\")\n",
    "print(f\"Test Masks:      {len(test_masks)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load sample image to check dimensions\n",
    "if len(train_images) > 0:\n",
    "    sample_img = cv2.imread(train_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "    sample_mask = cv2.imread(train_masks[0], cv2.IMREAD_GRAYSCALE)\n",
    "    print(f\"\\nOriginal Image Shape:  {sample_img.shape}\")\n",
    "    print(f\"Original Mask Shape:   {sample_mask.shape}\")\n",
    "    print(f\"Image dtype:           {sample_img.dtype}\")\n",
    "    print(f\"Mask dtype:            {sample_mask.dtype}\")\n",
    "    print(f\"Image value range:     [{sample_img.min()}, {sample_img.max()}]\")\n",
    "    print(f\"Mask unique values:    {np.unique(sample_mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e25b5",
   "metadata": {},
   "source": [
    "## 3. Visualize Random Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from training set\n",
    "np.random.seed(42)\n",
    "n_samples = 8\n",
    "indices = np.random.choice(len(train_images), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 3, figsize=(12, 3*n_samples))\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Load image and mask\n",
    "    img = cv2.imread(train_images[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(train_masks[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Overlay mask on image\n",
    "    overlay = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    overlay[mask > 0] = [255, 0, 0]  # Red overlay\n",
    "    \n",
    "    # Plot\n",
    "    axes[i, 0].imshow(img, cmap='gray')\n",
    "    axes[i, 0].set_title(f'Image {Path(train_images[idx]).stem}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask, cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth Mask')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(overlay)\n",
    "    axes[i, 2].set_title('Overlay')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Random Samples from Training Set', y=1.001, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d50be6",
   "metadata": {},
   "source": [
    "## 4. Analyze Image Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze intensity distributions\n",
    "n_analyze = 100  # Analyze subset for speed\n",
    "sample_indices = np.random.choice(len(train_images), n_analyze, replace=False)\n",
    "\n",
    "intensities = []\n",
    "mask_ratios = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    img = cv2.imread(train_images[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(train_masks[idx], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    intensities.extend(img.flatten())\n",
    "    mask_ratios.append(np.sum(mask > 0) / mask.size)\n",
    "\n",
    "# Plot intensity distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(intensities, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Pixel Intensity Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Pixel Intensity')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(mask_ratios, bins=30, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Mask Coverage Ratio Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Mask Coverage Ratio')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean mask coverage: {np.mean(mask_ratios):.4f}\")\n",
    "print(f\"Std mask coverage:  {np.std(mask_ratios):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503c49b",
   "metadata": {},
   "source": [
    "## 5. Visualize Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations on a single image\n",
    "import torch\n",
    "\n",
    "# Get transforms\n",
    "train_transforms = get_transforms(256, 256, is_train=True)\n",
    "\n",
    "# Load one image\n",
    "sample_img = cv2.imread(train_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "sample_mask = cv2.imread(train_masks[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply augmentation multiple times\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    # Apply transform\n",
    "    augmented = train_transforms(image=sample_img, mask=sample_mask)\n",
    "    aug_img = augmented['image'].squeeze().numpy()\n",
    "    aug_mask = augmented['mask'].squeeze().numpy()\n",
    "    \n",
    "    # Create overlay\n",
    "    overlay = np.stack([aug_img, aug_img, aug_img], axis=-1)\n",
    "    overlay[aug_mask > 0.5] = [1.0, 0.0, 0.0]\n",
    "    \n",
    "    axes[i].imshow(overlay)\n",
    "    axes[i].set_title(f'Augmentation {i+1}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples (HFlip, Rotation ±20°, Shift/Scale ±10%)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d043439",
   "metadata": {},
   "source": [
    "## 6. Pixel Size and HC Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dffefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files with pixel size and HC measurements\n",
    "train_csv = pd.read_csv('../dataset/training_set_pixel_size_and_HC.csv')\n",
    "test_csv = pd.read_csv('../dataset/test_set_pixel_size.csv')\n",
    "\n",
    "print(\"Training Set CSV:\")\n",
    "print(train_csv.head())\n",
    "print(f\"\\nShape: {train_csv.shape}\")\n",
    "print(f\"\\nColumns: {train_csv.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nTest Set CSV:\")\n",
    "print(test_csv.head())\n",
    "print(f\"\\nShape: {test_csv.shape}\")\n",
    "\n",
    "# Visualize HC distribution\n",
    "if 'head_circumference_mm' in train_csv.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].hist(train_csv['head_circumference_mm'], bins=30, \n",
    "                 color='mediumseagreen', alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_title('Head Circumference Distribution (Training)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Head Circumference (mm)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].hist(train_csv['pixel_size_mm'], bins=30, \n",
    "                 color='mediumpurple', alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_title('Pixel Size Distribution (Training)', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Pixel Size (mm)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nHC Stats: Mean={train_csv['head_circumference_mm'].mean():.2f} mm, \"\n",
    "          f\"Std={train_csv['head_circumference_mm'].std():.2f} mm\")\n",
    "    print(f\"Pixel Size Stats: Mean={train_csv['pixel_size_mm'].mean():.4f} mm, \"\n",
    "          f\"Std={train_csv['pixel_size_mm'].std():.4f} mm\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
