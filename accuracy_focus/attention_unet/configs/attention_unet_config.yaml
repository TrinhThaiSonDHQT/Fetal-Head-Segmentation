# Attention U-Net Configuration File

# Data Paths
data:
  train_images: 'shared/dataset/training_set/images'
  train_masks: 'shared/dataset/training_set/masks'
  val_images: 'shared/dataset/validation_set/images'
  val_masks: 'shared/dataset/validation_set/masks'

# Model Architecture
model:
  name: 'AttentionUNet'
  in_channels: 1
  out_channels: 1
  base_filters: 64

# Training Hyperparameters
training:
  batch_size: 16
  num_epochs: 100
  num_workers: 2
  pin_memory: true
  early_stopping_patience: 20

  # Optimizer
  optimizer:
    name: 'Adam'
    lr: 0.0001
    # lr: 0.00005  # or 5e-5
    betas: [0.9, 0.999]
    eps: 1.0e-8
    weight_decay: 1.0e-5 # or 1e-4

  # Learning Rate Scheduler
  scheduler:
    name: 'ReduceLROnPlateau'
    mode: 'max' # 'max' because we monitor val_dice (higher is better)
    factor: 0.5
    patience: 15
    min_lr: 1.0e-7
    verbose: true

# Loss Function
loss:
  name: 'DiceLoss'

# Logging and Checkpointing
logging:
  checkpoint_dir: 'accuracy_focus/attention_unet/results/checkpoints'
  log_dir: 'accuracy_focus/attention_unet/results/logs'
  prediction_dir: 'accuracy_focus/attention_unet/results/predictions'
  visualization_dir: 'accuracy_focus/attention_unet/results/visualizations'
  save_every_n_epochs: 5
  save_best_only: true
  visualize_every_n_epochs: 5

# Target Performance Metrics
target_metrics:
  dice: 0.9781 # DSC ≥97.81%
  iou: 0.9790 # mIoU ≥97.90%
  pixel_accuracy: 0.9918 # mPA ≥99.18%

# Device
device: 'cuda' # 'cuda' or 'cpu'

# Random Seed (for reproducibility)
seed: 42
